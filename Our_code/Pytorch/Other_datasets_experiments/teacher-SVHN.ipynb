{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Wide-Resnet 40x2\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             432\n",
      "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
      "            Conv2d-3           [-1, 32, 32, 32]           4,608\n",
      "           Dropout-4           [-1, 32, 32, 32]               0\n",
      "       BatchNorm2d-5           [-1, 32, 32, 32]              64\n",
      "            Conv2d-6           [-1, 32, 32, 32]           9,216\n",
      "            Conv2d-7           [-1, 32, 32, 32]             512\n",
      "        wide_basic-8           [-1, 32, 32, 32]               0\n",
      "       BatchNorm2d-9           [-1, 32, 32, 32]              64\n",
      "           Conv2d-10           [-1, 32, 32, 32]           9,216\n",
      "          Dropout-11           [-1, 32, 32, 32]               0\n",
      "      BatchNorm2d-12           [-1, 32, 32, 32]              64\n",
      "           Conv2d-13           [-1, 32, 32, 32]           9,216\n",
      "       wide_basic-14           [-1, 32, 32, 32]               0\n",
      "      BatchNorm2d-15           [-1, 32, 32, 32]              64\n",
      "           Conv2d-16           [-1, 32, 32, 32]           9,216\n",
      "          Dropout-17           [-1, 32, 32, 32]               0\n",
      "      BatchNorm2d-18           [-1, 32, 32, 32]              64\n",
      "           Conv2d-19           [-1, 32, 32, 32]           9,216\n",
      "       wide_basic-20           [-1, 32, 32, 32]               0\n",
      "      BatchNorm2d-21           [-1, 32, 32, 32]              64\n",
      "           Conv2d-22           [-1, 32, 32, 32]           9,216\n",
      "          Dropout-23           [-1, 32, 32, 32]               0\n",
      "      BatchNorm2d-24           [-1, 32, 32, 32]              64\n",
      "           Conv2d-25           [-1, 32, 32, 32]           9,216\n",
      "       wide_basic-26           [-1, 32, 32, 32]               0\n",
      "      BatchNorm2d-27           [-1, 32, 32, 32]              64\n",
      "           Conv2d-28           [-1, 32, 32, 32]           9,216\n",
      "          Dropout-29           [-1, 32, 32, 32]               0\n",
      "      BatchNorm2d-30           [-1, 32, 32, 32]              64\n",
      "           Conv2d-31           [-1, 32, 32, 32]           9,216\n",
      "       wide_basic-32           [-1, 32, 32, 32]               0\n",
      "      BatchNorm2d-33           [-1, 32, 32, 32]              64\n",
      "           Conv2d-34           [-1, 32, 32, 32]           9,216\n",
      "          Dropout-35           [-1, 32, 32, 32]               0\n",
      "      BatchNorm2d-36           [-1, 32, 32, 32]              64\n",
      "           Conv2d-37           [-1, 32, 32, 32]           9,216\n",
      "       wide_basic-38           [-1, 32, 32, 32]               0\n",
      "      BatchNorm2d-39           [-1, 32, 32, 32]              64\n",
      "           Conv2d-40           [-1, 64, 16, 16]          18,432\n",
      "          Dropout-41           [-1, 64, 16, 16]               0\n",
      "      BatchNorm2d-42           [-1, 64, 16, 16]             128\n",
      "           Conv2d-43           [-1, 64, 16, 16]          36,864\n",
      "           Conv2d-44           [-1, 64, 16, 16]           2,048\n",
      "       wide_basic-45           [-1, 64, 16, 16]               0\n",
      "      BatchNorm2d-46           [-1, 64, 16, 16]             128\n",
      "           Conv2d-47           [-1, 64, 16, 16]          36,864\n",
      "          Dropout-48           [-1, 64, 16, 16]               0\n",
      "      BatchNorm2d-49           [-1, 64, 16, 16]             128\n",
      "           Conv2d-50           [-1, 64, 16, 16]          36,864\n",
      "       wide_basic-51           [-1, 64, 16, 16]               0\n",
      "      BatchNorm2d-52           [-1, 64, 16, 16]             128\n",
      "           Conv2d-53           [-1, 64, 16, 16]          36,864\n",
      "          Dropout-54           [-1, 64, 16, 16]               0\n",
      "      BatchNorm2d-55           [-1, 64, 16, 16]             128\n",
      "           Conv2d-56           [-1, 64, 16, 16]          36,864\n",
      "       wide_basic-57           [-1, 64, 16, 16]               0\n",
      "      BatchNorm2d-58           [-1, 64, 16, 16]             128\n",
      "           Conv2d-59           [-1, 64, 16, 16]          36,864\n",
      "          Dropout-60           [-1, 64, 16, 16]               0\n",
      "      BatchNorm2d-61           [-1, 64, 16, 16]             128\n",
      "           Conv2d-62           [-1, 64, 16, 16]          36,864\n",
      "       wide_basic-63           [-1, 64, 16, 16]               0\n",
      "      BatchNorm2d-64           [-1, 64, 16, 16]             128\n",
      "           Conv2d-65           [-1, 64, 16, 16]          36,864\n",
      "          Dropout-66           [-1, 64, 16, 16]               0\n",
      "      BatchNorm2d-67           [-1, 64, 16, 16]             128\n",
      "           Conv2d-68           [-1, 64, 16, 16]          36,864\n",
      "       wide_basic-69           [-1, 64, 16, 16]               0\n",
      "      BatchNorm2d-70           [-1, 64, 16, 16]             128\n",
      "           Conv2d-71           [-1, 64, 16, 16]          36,864\n",
      "          Dropout-72           [-1, 64, 16, 16]               0\n",
      "      BatchNorm2d-73           [-1, 64, 16, 16]             128\n",
      "           Conv2d-74           [-1, 64, 16, 16]          36,864\n",
      "       wide_basic-75           [-1, 64, 16, 16]               0\n",
      "      BatchNorm2d-76           [-1, 64, 16, 16]             128\n",
      "           Conv2d-77            [-1, 128, 8, 8]          73,728\n",
      "          Dropout-78            [-1, 128, 8, 8]               0\n",
      "      BatchNorm2d-79            [-1, 128, 8, 8]             256\n",
      "           Conv2d-80            [-1, 128, 8, 8]         147,456\n",
      "           Conv2d-81            [-1, 128, 8, 8]           8,192\n",
      "       wide_basic-82            [-1, 128, 8, 8]               0\n",
      "      BatchNorm2d-83            [-1, 128, 8, 8]             256\n",
      "           Conv2d-84            [-1, 128, 8, 8]         147,456\n",
      "          Dropout-85            [-1, 128, 8, 8]               0\n",
      "      BatchNorm2d-86            [-1, 128, 8, 8]             256\n",
      "           Conv2d-87            [-1, 128, 8, 8]         147,456\n",
      "       wide_basic-88            [-1, 128, 8, 8]               0\n",
      "      BatchNorm2d-89            [-1, 128, 8, 8]             256\n",
      "           Conv2d-90            [-1, 128, 8, 8]         147,456\n",
      "          Dropout-91            [-1, 128, 8, 8]               0\n",
      "      BatchNorm2d-92            [-1, 128, 8, 8]             256\n",
      "           Conv2d-93            [-1, 128, 8, 8]         147,456\n",
      "       wide_basic-94            [-1, 128, 8, 8]               0\n",
      "      BatchNorm2d-95            [-1, 128, 8, 8]             256\n",
      "           Conv2d-96            [-1, 128, 8, 8]         147,456\n",
      "          Dropout-97            [-1, 128, 8, 8]               0\n",
      "      BatchNorm2d-98            [-1, 128, 8, 8]             256\n",
      "           Conv2d-99            [-1, 128, 8, 8]         147,456\n",
      "      wide_basic-100            [-1, 128, 8, 8]               0\n",
      "     BatchNorm2d-101            [-1, 128, 8, 8]             256\n",
      "          Conv2d-102            [-1, 128, 8, 8]         147,456\n",
      "         Dropout-103            [-1, 128, 8, 8]               0\n",
      "     BatchNorm2d-104            [-1, 128, 8, 8]             256\n",
      "          Conv2d-105            [-1, 128, 8, 8]         147,456\n",
      "      wide_basic-106            [-1, 128, 8, 8]               0\n",
      "     BatchNorm2d-107            [-1, 128, 8, 8]             256\n",
      "          Conv2d-108            [-1, 128, 8, 8]         147,456\n",
      "         Dropout-109            [-1, 128, 8, 8]               0\n",
      "     BatchNorm2d-110            [-1, 128, 8, 8]             256\n",
      "          Conv2d-111            [-1, 128, 8, 8]         147,456\n",
      "      wide_basic-112            [-1, 128, 8, 8]               0\n",
      "     BatchNorm2d-113            [-1, 128, 8, 8]             256\n",
      "          Linear-114                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 2,243,546\n",
      "Trainable params: 2,243,546\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 16.44\n",
      "Params size (MB): 8.56\n",
      "Estimated Total Size (MB): 25.01\n",
      "----------------------------------------------------------------\n",
      "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to /home/test/data/train_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to /home/test/data/test_32x32.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1:\n",
      "\t Training loss: \t 0.009016, \t Training accuracy \t 60.28\n",
      "\t Validation loss: \t 0.005981,\t Validation accuracy \t 75.68\n",
      "Epoch: 2:\n",
      "\t Training loss: \t 0.004127, \t Training accuracy \t 83.49\n",
      "\t Validation loss: \t 0.004385,\t Validation accuracy \t 82.38\n",
      "Epoch: 3:\n",
      "\t Training loss: \t 0.003506, \t Training accuracy \t 86.01\n",
      "\t Validation loss: \t 0.004053,\t Validation accuracy \t 84.15\n",
      "Epoch: 4:\n",
      "\t Training loss: \t 0.003284, \t Training accuracy \t 87.01\n",
      "\t Validation loss: \t 0.003808,\t Validation accuracy \t 85.25\n",
      "Epoch: 5:\n",
      "\t Training loss: \t 0.003104, \t Training accuracy \t 87.79\n",
      "\t Validation loss: \t 0.003890,\t Validation accuracy \t 85.11\n",
      "Epoch: 6:\n",
      "\t Training loss: \t 0.003070, \t Training accuracy \t 87.91\n",
      "\t Validation loss: \t 0.004007,\t Validation accuracy \t 84.56\n",
      "Epoch: 7:\n",
      "\t Training loss: \t 0.003000, \t Training accuracy \t 88.25\n",
      "\t Validation loss: \t 0.003373,\t Validation accuracy \t 87.30\n",
      "Epoch: 8:\n",
      "\t Training loss: \t 0.002944, \t Training accuracy \t 88.48\n",
      "\t Validation loss: \t 0.003600,\t Validation accuracy \t 86.20\n",
      "Epoch: 9:\n",
      "\t Training loss: \t 0.002874, \t Training accuracy \t 88.75\n",
      "\t Validation loss: \t 0.003051,\t Validation accuracy \t 88.66\n",
      "Test loss: \t 0.002631, \t \t Test accuracy \t 89.64\n",
      "Epoch: 10:\n",
      "\t Training loss: \t 0.002850, \t Training accuracy \t 88.90\n",
      "\t Validation loss: \t 0.003819,\t Validation accuracy \t 86.75\n",
      "Epoch: 11:\n",
      "\t Training loss: \t 0.002780, \t Training accuracy \t 89.09\n",
      "\t Validation loss: \t 0.003834,\t Validation accuracy \t 86.34\n",
      "Epoch: 12:\n",
      "\t Training loss: \t 0.002743, \t Training accuracy \t 89.34\n",
      "\t Validation loss: \t 0.003157,\t Validation accuracy \t 89.07\n",
      "Epoch: 13:\n",
      "\t Training loss: \t 0.002660, \t Training accuracy \t 89.69\n",
      "\t Validation loss: \t 0.003446,\t Validation accuracy \t 87.16\n",
      "Epoch: 14:\n",
      "\t Training loss: \t 0.002660, \t Training accuracy \t 89.65\n",
      "\t Validation loss: \t 0.003046,\t Validation accuracy \t 88.66\n",
      "Epoch: 15:\n",
      "\t Training loss: \t 0.002645, \t Training accuracy \t 89.73\n",
      "\t Validation loss: \t 0.003086,\t Validation accuracy \t 88.11\n",
      "Epoch: 16:\n",
      "\t Training loss: \t 0.002607, \t Training accuracy \t 89.92\n",
      "\t Validation loss: \t 0.003023,\t Validation accuracy \t 88.25\n",
      "Epoch: 17:\n",
      "\t Training loss: \t 0.002578, \t Training accuracy \t 90.01\n",
      "\t Validation loss: \t 0.002966,\t Validation accuracy \t 89.48\n",
      "Epoch: 18:\n",
      "\t Training loss: \t 0.002565, \t Training accuracy \t 90.05\n",
      "\t Validation loss: \t 0.003140,\t Validation accuracy \t 88.11\n",
      "Test loss: \t 0.002305, \t \t Test accuracy \t 91.18\n",
      "Epoch: 19:\n",
      "\t Training loss: \t 0.002579, \t Training accuracy \t 90.10\n",
      "\t Validation loss: \t 0.002672,\t Validation accuracy \t 89.62\n",
      "Epoch: 20:\n",
      "\t Training loss: \t 0.002538, \t Training accuracy \t 90.16\n",
      "\t Validation loss: \t 0.003150,\t Validation accuracy \t 87.84\n",
      "Epoch: 21:\n",
      "\t Training loss: \t 0.002544, \t Training accuracy \t 90.21\n",
      "\t Validation loss: \t 0.002759,\t Validation accuracy \t 89.48\n",
      "Epoch: 22:\n",
      "\t Training loss: \t 0.002502, \t Training accuracy \t 90.35\n",
      "\t Validation loss: \t 0.003040,\t Validation accuracy \t 87.02\n",
      "Epoch: 23:\n",
      "\t Training loss: \t 0.002522, \t Training accuracy \t 90.39\n",
      "\t Validation loss: \t 0.003220,\t Validation accuracy \t 87.84\n",
      "Epoch: 24:\n",
      "\t Training loss: \t 0.002512, \t Training accuracy \t 90.25\n",
      "\t Validation loss: \t 0.004622,\t Validation accuracy \t 82.24\n",
      "Epoch: 25:\n",
      "\t Training loss: \t 0.002486, \t Training accuracy \t 90.41\n",
      "\t Validation loss: \t 0.002589,\t Validation accuracy \t 89.21\n",
      "Epoch: 26:\n",
      "\t Training loss: \t 0.002499, \t Training accuracy \t 90.35\n",
      "\t Validation loss: \t 0.002717,\t Validation accuracy \t 91.12\n",
      "Epoch: 27:\n",
      "\t Training loss: \t 0.002470, \t Training accuracy \t 90.43\n",
      "\t Validation loss: \t 0.002682,\t Validation accuracy \t 89.89\n",
      "Test loss: \t 0.001936, \t \t Test accuracy \t 92.83\n",
      "Epoch: 28:\n",
      "\t Training loss: \t 0.002472, \t Training accuracy \t 90.52\n",
      "\t Validation loss: \t 0.002734,\t Validation accuracy \t 89.21\n",
      "Epoch: 29:\n",
      "\t Training loss: \t 0.002467, \t Training accuracy \t 90.58\n",
      "\t Validation loss: \t 0.003150,\t Validation accuracy \t 87.16\n",
      "Epoch: 30:\n",
      "\t Training loss: \t 0.002444, \t Training accuracy \t 90.67\n",
      "\t Validation loss: \t 0.002797,\t Validation accuracy \t 90.16\n",
      "Epoch: 31:\n",
      "\t Training loss: \t 0.001648, \t Training accuracy \t 93.92\n",
      "\t Validation loss: \t 0.001474,\t Validation accuracy \t 94.54\n",
      "Epoch: 32:\n",
      "\t Training loss: \t 0.001505, \t Training accuracy \t 94.50\n",
      "\t Validation loss: \t 0.001557,\t Validation accuracy \t 93.99\n",
      "Epoch: 33:\n",
      "\t Training loss: \t 0.001484, \t Training accuracy \t 94.55\n",
      "\t Validation loss: \t 0.001774,\t Validation accuracy \t 93.99\n",
      "Epoch: 34:\n",
      "\t Training loss: \t 0.001467, \t Training accuracy \t 94.65\n",
      "\t Validation loss: \t 0.001445,\t Validation accuracy \t 95.22\n",
      "Epoch: 35:\n",
      "\t Training loss: \t 0.001453, \t Training accuracy \t 94.76\n",
      "\t Validation loss: \t 0.001555,\t Validation accuracy \t 94.40\n",
      "Epoch: 36:\n",
      "\t Training loss: \t 0.001457, \t Training accuracy \t 94.64\n",
      "\t Validation loss: \t 0.001499,\t Validation accuracy \t 94.13\n",
      "Test loss: \t 0.001373, \t \t Test accuracy \t 95.02\n",
      "Epoch: 37:\n",
      "\t Training loss: \t 0.001457, \t Training accuracy \t 94.67\n",
      "\t Validation loss: \t 0.001469,\t Validation accuracy \t 94.54\n",
      "Epoch: 38:\n",
      "\t Training loss: \t 0.001466, \t Training accuracy \t 94.59\n",
      "\t Validation loss: \t 0.001545,\t Validation accuracy \t 94.40\n",
      "Epoch: 39:\n",
      "\t Training loss: \t 0.001461, \t Training accuracy \t 94.60\n",
      "\t Validation loss: \t 0.001679,\t Validation accuracy \t 93.17\n",
      "Epoch: 40:\n",
      "\t Training loss: \t 0.001502, \t Training accuracy \t 94.46\n",
      "\t Validation loss: \t 0.001630,\t Validation accuracy \t 93.44\n",
      "Epoch: 41:\n",
      "\t Training loss: \t 0.001472, \t Training accuracy \t 94.63\n",
      "\t Validation loss: \t 0.001634,\t Validation accuracy \t 94.40\n",
      "Epoch: 42:\n",
      "\t Training loss: \t 0.001475, \t Training accuracy \t 94.57\n",
      "\t Validation loss: \t 0.001646,\t Validation accuracy \t 94.13\n",
      "Epoch: 43:\n",
      "\t Training loss: \t 0.001489, \t Training accuracy \t 94.53\n",
      "\t Validation loss: \t 0.001685,\t Validation accuracy \t 93.99\n",
      "Epoch: 44:\n",
      "\t Training loss: \t 0.001501, \t Training accuracy \t 94.51\n",
      "\t Validation loss: \t 0.001813,\t Validation accuracy \t 93.03\n",
      "Epoch: 45:\n",
      "\t Training loss: \t 0.001500, \t Training accuracy \t 94.43\n",
      "\t Validation loss: \t 0.001620,\t Validation accuracy \t 94.26\n",
      "Test loss: \t 0.001199, \t \t Test accuracy \t 95.66\n",
      "Epoch: 46:\n",
      "\t Training loss: \t 0.001496, \t Training accuracy \t 94.48\n",
      "\t Validation loss: \t 0.001843,\t Validation accuracy \t 94.13\n",
      "Epoch: 47:\n",
      "\t Training loss: \t 0.001479, \t Training accuracy \t 94.51\n",
      "\t Validation loss: \t 0.001398,\t Validation accuracy \t 94.95\n",
      "Epoch: 48:\n",
      "\t Training loss: \t 0.001490, \t Training accuracy \t 94.49\n",
      "\t Validation loss: \t 0.001969,\t Validation accuracy \t 93.17\n",
      "Epoch: 49:\n",
      "\t Training loss: \t 0.001468, \t Training accuracy \t 94.61\n",
      "\t Validation loss: \t 0.001595,\t Validation accuracy \t 94.40\n",
      "Epoch: 50:\n",
      "\t Training loss: \t 0.001472, \t Training accuracy \t 94.59\n",
      "\t Validation loss: \t 0.001757,\t Validation accuracy \t 94.26\n",
      "Epoch: 51:\n",
      "\t Training loss: \t 0.001467, \t Training accuracy \t 94.62\n",
      "\t Validation loss: \t 0.001862,\t Validation accuracy \t 93.44\n",
      "Epoch: 52:\n",
      "\t Training loss: \t 0.001469, \t Training accuracy \t 94.59\n",
      "\t Validation loss: \t 0.002045,\t Validation accuracy \t 91.53\n",
      "Epoch: 53:\n",
      "\t Training loss: \t 0.001465, \t Training accuracy \t 94.56\n",
      "\t Validation loss: \t 0.001571,\t Validation accuracy \t 94.54\n",
      "Epoch: 54:\n",
      "\t Training loss: \t 0.001469, \t Training accuracy \t 94.59\n",
      "\t Validation loss: \t 0.001587,\t Validation accuracy \t 93.58\n",
      "Test loss: \t 0.001511, \t \t Test accuracy \t 94.47\n",
      "Epoch: 55:\n",
      "\t Training loss: \t 0.001452, \t Training accuracy \t 94.55\n",
      "\t Validation loss: \t 0.001507,\t Validation accuracy \t 94.95\n",
      "Epoch: 56:\n",
      "\t Training loss: \t 0.001445, \t Training accuracy \t 94.72\n",
      "\t Validation loss: \t 0.001861,\t Validation accuracy \t 92.76\n",
      "Epoch: 57:\n",
      "\t Training loss: \t 0.001452, \t Training accuracy \t 94.58\n",
      "\t Validation loss: \t 0.001730,\t Validation accuracy \t 93.85\n",
      "Epoch: 58:\n",
      "\t Training loss: \t 0.001445, \t Training accuracy \t 94.62\n",
      "\t Validation loss: \t 0.001630,\t Validation accuracy \t 94.40\n",
      "Epoch: 59:\n",
      "\t Training loss: \t 0.001438, \t Training accuracy \t 94.71\n",
      "\t Validation loss: \t 0.001502,\t Validation accuracy \t 95.63\n",
      "Epoch: 60:\n",
      "\t Training loss: \t 0.001439, \t Training accuracy \t 94.66\n",
      "\t Validation loss: \t 0.001655,\t Validation accuracy \t 94.95\n",
      "Epoch: 61:\n",
      "\t Training loss: \t 0.001053, \t Training accuracy \t 96.27\n",
      "\t Validation loss: \t 0.001390,\t Validation accuracy \t 95.63\n",
      "Epoch: 62:\n",
      "\t Training loss: \t 0.000942, \t Training accuracy \t 96.69\n",
      "\t Validation loss: \t 0.001428,\t Validation accuracy \t 94.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63:\n",
      "\t Training loss: \t 0.000896, \t Training accuracy \t 96.85\n",
      "\t Validation loss: \t 0.001212,\t Validation accuracy \t 96.04\n",
      "Test loss: \t 0.001057, \t \t Test accuracy \t 96.40\n",
      "Epoch: 64:\n",
      "\t Training loss: \t 0.000866, \t Training accuracy \t 96.96\n",
      "\t Validation loss: \t 0.001414,\t Validation accuracy \t 95.22\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-dbeb2345ed9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;31m# Call the main\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_percentage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-dbeb2345ed9f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(epochs, batch_size, test_batch_size, val_percentage, lr, test_freq, net_depth, net_width)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcost_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcost_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-dbeb2345ed9f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_loader, net, cost_fun, device, optimizer)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tmp/advanceddeep/our_code/Pytorch/wideresnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mact1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mact2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tmp/advanceddeep/our_code/Pytorch/wideresnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1654\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1655\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1656\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1657\u001b[0m     )\n\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Modify Lab3 - 04-15-2019 - Medium.ipynb\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from wideresnet import Wide_ResNet\n",
    "\n",
    "\n",
    "'''\n",
    "Function that loads the dataset and returns the data-loaders\n",
    "'''\n",
    "def getData(batch_size,test_batch_size,val_percentage):\n",
    "    # Normalize the training set with data augmentation\n",
    "    transform_train = transforms.Compose([ \n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.RandomRotation(20),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "    \n",
    "    # Normalize the test set same as training set without augmentation\n",
    "    transform_test = transforms.Compose([ \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n",
    "\n",
    "    # Download/Load data\n",
    "    full_training_data = torchvision.datasets.SVHN('/home/test/data',split='train',transform=transform_train,download=True)  \n",
    "    test_data = torchvision.datasets.SVHN('/home/test/data',split='test',transform=transform_test,download=True)  \n",
    "\n",
    "    # Create train and validation splits\n",
    "    num_samples = len(full_training_data)\n",
    "    training_samples = int((1-val_percentage)*num_samples+1)\n",
    "    validation_samples = num_samples - training_samples\n",
    "    training_data, validation_data = torch.utils.data.random_split(full_training_data, [training_samples, validation_samples])\n",
    "\n",
    "    # Initialize dataloaders\n",
    "    train_loader = torch.utils.data.DataLoader(training_data,batch_size=batch_size,shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(validation_data,batch_size=batch_size,shuffle=False)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data,batch_size=test_batch_size,shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "'''\n",
    "Function to test that returns the loss per sample and the total accuracy\n",
    "'''\n",
    "def test(data_loader,net,cost_fun,device):\n",
    "  \n",
    "    net.eval()\n",
    "    samples = 0.\n",
    "    cumulative_loss = 0.\n",
    "    cumulative_accuracy = 0.\n",
    "\n",
    "    for batch_idx, (inputs,targets) in enumerate(data_loader):\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        outputs = net(inputs)[0]\n",
    "        loss = cost_fun(outputs,targets)\n",
    "\n",
    "        # Metrics computation\n",
    "        samples+=inputs.shape[0]\n",
    "        cumulative_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        cumulative_accuracy += predicted.eq(targets).sum().item()\n",
    "\n",
    "    return cumulative_loss/samples, cumulative_accuracy/samples*100\n",
    "\n",
    "'''\n",
    "Function to train the nework on the data for one epoch that returns the loss per sample and the total accuracy\n",
    "'''\n",
    "def train(data_loader,net,cost_fun,device,optimizer):\n",
    "    \n",
    "    net.train()\n",
    "    samples = 0.\n",
    "    cumulative_loss = 0.\n",
    "    cumulative_accuracy = 0.\n",
    "\n",
    "    for batch_idx, (inputs,targets) in enumerate(data_loader):\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        outputs = net(inputs)[0]\n",
    "        loss = cost_fun(outputs,targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Metrics computation\n",
    "        samples+=inputs.shape[0]\n",
    "        cumulative_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        cumulative_accuracy += predicted.eq(targets).sum().item()\n",
    "\n",
    "    return cumulative_loss/samples, cumulative_accuracy/samples*100\n",
    "\n",
    "def main(epochs, batch_size, test_batch_size,val_percentage,lr,test_freq, net_depth, net_width):\n",
    "    \n",
    "    # Define cost function\n",
    "    cost_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Create the network: Wide_ResNet(depth, width, dropout, num_classes)\n",
    "    net = Wide_ResNet(net_depth,net_width,0,10)\n",
    "    net = net.to(device)\n",
    "    summary(net,input_size=(3,32,32))\n",
    "\n",
    "    # Create the optimizer anche the learning rate scheduler\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, \n",
    "                    milestones=[int(epochs*0.3),int(epochs*0.6),int(epochs*0.8)], gamma=0.20)\n",
    "\n",
    "    # Get the data\n",
    "    train_loader, val_loader, test_loader = getData(batch_size,test_batch_size,val_percentage)\n",
    "    \n",
    "    save_filename = './SVHN-teacher-' + str(net_depth) + '-' + str(net_width) + '.pth'\n",
    "\n",
    "    for e in range(epochs):\n",
    "        net.train() \n",
    "\n",
    "        train_loss, train_accuracy = train(train_loader,net,cost_function,device,optimizer)\n",
    "\n",
    "        val_loss, val_accuracy = test(val_loader,net,cost_function,device)\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        print('Epoch: {:d}:'.format(e+1))\n",
    "        print('\\t Training loss: \\t {:.6f}, \\t Training accuracy \\t {:.2f}'.format(train_loss, train_accuracy))\n",
    "        print('\\t Validation loss: \\t {:.6f},\\t Validation accuracy \\t {:.2f}'.format(val_loss, val_accuracy))\n",
    "        \n",
    "        if((e+1) % test_freq) == 0:\n",
    "            test_loss, test_accuracy = test(test_loader,net,cost_function,device)\n",
    "            torch.save(net.state_dict(), save_filename)\n",
    "            print('Test loss: \\t {:.6f}, \\t \\t Test accuracy \\t {:.2f}'.format(test_loss, test_accuracy))\n",
    "\n",
    "    print('After training:')\n",
    "    train_loss, train_accuracy = test(train_loader,net,cost_function,device)\n",
    "    val_loss, val_accuracy = test(val_loader,net,cost_function,device)\n",
    "    test_loss, test_accuracy = test(test_loader,net,cost_function,device)\n",
    "\n",
    "    print('\\t Training loss: \\t {:.6f}, \\t Training accuracy \\t {:.2f}'.format(train_loss, train_accuracy))\n",
    "    print('\\t Validation loss: \\t {:.6f},\\t Validation accuracy \\t {:.2f}'.format(val_loss, val_accuracy))\n",
    "    print('Test loss: \\t {:.6f}, \\t \\t Test accuracy \\t {:.2f}'.format(test_loss, test_accuracy))\n",
    "    \n",
    "    torch.save(net.state_dict(), save_filename)\n",
    "\n",
    "    net2 = Wide_ResNet(net_depth,net_width,0,10)\n",
    "    net2 = net.to(device)\n",
    "    net2.load_state_dict(torch.load(save_filename))\n",
    "    \n",
    "    print('loaded net test:')\n",
    "    test_loss, test_accuracy = test(test_loader,net2,cost_function,device)\n",
    "    print('\\t Test loss: \\t {:.6f}, \\t Test accuracy \\t {:.2f}'.format(test_loss, test_accuracy))\n",
    "\n",
    "    \n",
    "# Parameters\n",
    "epochs = 100\n",
    "batch_size = 128\n",
    "test_batch_size = 128\n",
    "val_percentage = 0.01\n",
    "lr = 0.1\n",
    "test_freq = 9\n",
    "device = 'cuda:0'\n",
    "net_depth = 40\n",
    "net_width = 2\n",
    "\n",
    "\n",
    "# Call the main\n",
    "main(epochs, batch_size, test_batch_size,val_percentage,lr,test_freq, net_depth, net_width)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_gpuenv",
   "language": "python",
   "name": "tensorflow_gpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
