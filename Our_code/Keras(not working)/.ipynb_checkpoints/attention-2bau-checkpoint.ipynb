{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10 loaded\n",
      "Generator loaded\n",
      "Teacher loaded from./pretrained_models/wrn_16_2.h5\n",
      "Wide Residual Network-16-1 created.\n",
      "Simple student loaded\n",
      "out for the stud\n",
      "(4, 2708)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor Tensor(\"input_28:0\", shape=(?, 10), dtype=float32) at layer \"input_28\". The following previous layers were accessed without issue: ['input_27', 'sequential_3']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5a8b75714cfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;31m#print('Student test loss: '  + str(score))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-5a8b75714cfa>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteacher\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstudent_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m     \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-5a8b75714cfa>\u001b[0m in \u001b[0;36mgetGAN\u001b[0;34m(teacher, student, generator)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m     93\u001b[0m             \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name, **kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         nodes, nodes_by_depth, layers, layers_by_depth = _map_graph_network(\n\u001b[0;32m--> 241\u001b[0;31m             self.inputs, self.outputs)\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m                                          \u001b[0;34m'The following previous layers '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m                                          \u001b[0;34m'were accessed without issue: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m                                          str(layers_with_complete_input))\n\u001b[0m\u001b[1;32m   1512\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m                     \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor Tensor(\"input_28:0\", shape=(?, 10), dtype=float32) at layer \"input_28\". The following previous layers were accessed without issue: ['input_27', 'sequential_3']"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import keras\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from ourwrnet import create_wide_residual_network\n",
    "from new_stud import create_wide_residual_network_student\n",
    "from cifar10utils import getCIFAR10, getCIFAR10InputShape\n",
    "\n",
    "\n",
    "'''\n",
    "Function that loads from a file the teacher\n",
    "'''\n",
    "def getTeacher(file_name):\n",
    "    with open(file_name + '.json', 'r') as f:\n",
    "        model = model_from_json(f.read())\n",
    "    model.load_weights(file_name + '.h5')\n",
    "    \n",
    "    with open(file_name + '_layer1.json', 'r') as f:\n",
    "        m1 = model_from_json(f.read())\n",
    "    m1.load_weights(file_name + '_layer1.h5')\n",
    "    \n",
    "    with open(file_name + '_layer2.json', 'r') as f:\n",
    "        m2 = model_from_json(f.read())\n",
    "    m2.load_weights(file_name + '_layer2.h5')\n",
    "    \n",
    "    with open(file_name + '_layer3.json', 'r') as f:\n",
    "        m3 = model_from_json(f.read())\n",
    "    m3.load_weights(file_name + '_layer3.h5')    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print('Teacher loaded from' + file_name + '.h5')\n",
    "    return model,m1,m2,m3\n",
    "    \n",
    "'''\n",
    "Function that loads from a file the teacher and test it on the CIRAF10 dataset\n",
    "'''\n",
    "def testTeacher(file_name):\n",
    "    x_train,y_train,x_test,y_test = getCIFAR10()\n",
    "    model = getTeacher(file_name)\n",
    "    opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=opt_rms, metrics=['accuracy'])\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Teacher test loss:', score[0])\n",
    "    print('Teacher test accuracy:', score[1])\n",
    "    \n",
    "'''\n",
    "Function that returns a simple student done by 2 convolutions, a maxpool and a final two fully connected layers\n",
    "'''\n",
    "def getStudent(input_shape):\n",
    "    num_classes = 10\n",
    "    \n",
    "    model_train, copy,m1,m2,m3 = create_wide_residual_network_student(input_shape, nb_classes=10, N=2,k=1)\n",
    "    \n",
    "    print('Simple student loaded')\n",
    "    return model_train, copy,m1,m2,m3\n",
    "\n",
    "'''\n",
    "Function that returns a simple generator\n",
    "'''\n",
    "def getGenerator():\n",
    "\n",
    "    noise_shape = (100,)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    img_shape = getCIFAR10InputShape()\n",
    "\n",
    "    model.add(Dense(128*8**2, input_shape=noise_shape))\n",
    "    model.add(Reshape((8, 8, 128)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2)) \n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Conv2D(3, kernel_size=(3,3), strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization())   \n",
    "\n",
    "    #model.summary()\n",
    "    print('Generator loaded')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def getGAN(teacher,student,generator): #modified\n",
    "    \n",
    "    z = Input(shape=(100,))\n",
    "    img = generator(z)\n",
    "    \n",
    "    ta_pred = Input(shape=(10,))\n",
    "    ta1 = Input(shape=(1024,))\n",
    "    ta2 = Input(shape=(256,))\n",
    "    ta3 = Input(shape=(64,))\n",
    "    \n",
    "    sa1 = Input(shape=(1024,))\n",
    "    sa2 = Input(shape=(256,))\n",
    "    sa3 = Input(shape=(64,))\n",
    "    \n",
    "    #student.trainable = False # it works if it is not true\n",
    "    teacher.trainable = False\n",
    "    \n",
    "    out_s = student([img,ta_pred,ta1,ta2,ta3,sa1,sa2,sa3])\n",
    "\n",
    "    \n",
    "    gan = Model([z,ta_pred,ta1,ta2,ta3,sa1,sa2,sa3],out_s)\n",
    "    \n",
    "    return gan\n",
    "\n",
    "def gan_loss(y_true, y_pred):\n",
    "    y_pred = y_pred[:,0:10]\n",
    "\n",
    "    loss = keras.losses.kullback_leibler_divergence(y_true, y_pred)\n",
    "    min_loss = (-(loss))\n",
    "    \n",
    "    return min_loss\n",
    "\n",
    "def attention_loss(ta,sa):\n",
    "    subtracted = (ta - sa)\n",
    "    \n",
    "    power2 = K.pow(subtracted,2)\n",
    "    \n",
    "    avg = K.mean(power2,-1)\n",
    "    \n",
    "    beta = 250\n",
    "    \n",
    "    return avg*beta\n",
    "\n",
    "def student_loss(y_true,y_pred): #modified\n",
    "    \n",
    "    #y_true = teacher predictions\n",
    "    #y_pred = student predictions\n",
    "    KDloss = keras.losses.kullback_leibler_divergence(y_true,y_pred)\n",
    "    \n",
    "    '''\n",
    "    attentionL = attention_loss(sa1,ta1)\n",
    "    \n",
    "    attentionL += attention_loss(sa2,ta2)\n",
    "    \n",
    "    attentionL += attention_loss(sa3,ta3)\n",
    "    \n",
    "    to_return = KDloss + attentionL'''\n",
    "    \n",
    "    return KDloss\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    x_train,y_train,x_test,y_test = getCIFAR10()\n",
    "    input_shape = getCIFAR10InputShape()\n",
    "    \n",
    "    optim_stud = Adam(lr=2e-3, clipnorm=5.0)\n",
    "    optim_gen = Adam(lr=1e-3, clipnorm=5.0)  \n",
    "    \n",
    "    generator = getGenerator()\n",
    "    \n",
    "    teacher, t_layer1, t_layer2,t_layer3 = getTeacher('./pretrained_models/wrn_16_2')\n",
    "    teacher.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
    "    t_layer1.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
    "    t_layer2.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
    "    t_layer3.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    noise = np.random.normal(0, 1, (4, 100))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "    t_predictions = teacher.predict(gen_imgs)\n",
    "    ta1 = t_layer1.predict(gen_imgs)[0]\n",
    "    ta2 = t_layer2.predict(gen_imgs)[0]\n",
    "    ta3 = t_layer3.predict(gen_imgs)[0]\n",
    "    \n",
    "    sa1 = t_layer1.predict(gen_imgs)[0]\n",
    "    sa2 = t_layer2.predict(gen_imgs)[0]\n",
    "    sa3 = t_layer3.predict(gen_imgs)[0]\n",
    "    \n",
    "    student_train, student_test, s_layer1, s_layer2, s_layer3 = getStudent(input_shape)\n",
    "    \n",
    "    student_test.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    student_train.compile(loss= student_loss, optimizer=optim_stud)\n",
    "    s_layer1.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam')\n",
    "    s_layer2.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam')\n",
    "    s_layer3.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam')\n",
    "    \n",
    "    out_stud = student_train.predict([gen_imgs,t_predictions,ta1,ta2,ta3,sa1,sa2,sa3])\n",
    "    \n",
    "    print('out for the stud')\n",
    "    print(str(out_stud.shape))\n",
    "    \n",
    "    \n",
    "    gan = getGAN(teacher,student_train,generator)\n",
    "    gan.summary()\n",
    "    \n",
    "    gan.compile(loss=gan_loss, optimizer=optim_gen)\n",
    "    \n",
    "    n_batches = 1000\n",
    "    batch_size = 128\n",
    "    log_freq = 10\n",
    "    ns = 10\n",
    "    \n",
    "    \n",
    "    print(\"loop starting:\")\n",
    "    \n",
    "    '''\n",
    "    for i in range(n_batches):\n",
    "        \n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "        \n",
    "        t_predictions = teacher.predict(gen_imgs)\n",
    "        s_predictions = student_train.predict(gen_imgs)\n",
    "        \n",
    "        gen_loss = gan.train_on_batch(noise,t_predictions)\n",
    "        \n",
    "        \n",
    "        t_predictions = teacher.predict(gen_imgs)\n",
    "        ta1 = t_layer1.predict(gen_imgs)[0]\n",
    "        ta2 = t_layer2.predict(gen_imgs)[0]\n",
    "        ta3 = t_layer3.predict(gen_imgs)[0]\n",
    "        \n",
    "        s_loss=0\n",
    "        for j in range(ns):\n",
    "            #s_predictions = student_train.predict(gen_imgs)\n",
    "            sa1 = s_layer1.predict(gen_imgs)[0]\n",
    "            sa2 = s_layer2.predict(gen_imgs)[0]\n",
    "            sa3 = s_layer3.predict(gen_imgs)[0]\n",
    "            \n",
    "            fake_lbl = K.zeros((batch_size,100))\n",
    "            \n",
    "            s_loss += student_train.train_on_batch(gen_imgs,fake_lbl)\n",
    "\n",
    "        \n",
    "        print('batch ' + str(i) + '/' + str(n_batches) + ' G loss: ' + str(gen_loss) + ' S loss: ' + str(s_loss/ns))\n",
    "        \n",
    "        '''\n",
    "    \n",
    "'''     \n",
    "        if (i % log_freq) == 0:\n",
    "            score = student_test.evaluate(x_test, y_test, verbose=0)\n",
    "            print('Student test loss: '  + str(score))\n",
    "            \n",
    "            model_json = student_test.to_json()\n",
    "            with open('tmp-model' + str(i) + '.json','w') as json_file:\n",
    "                json_file.write(model_json)\n",
    "            student_test.save_weights('tmp-model' + str(i) + '.h5')\n",
    "            print('saved model ' + str(i))\n",
    "   '''\n",
    "        \n",
    "    #score = student_test.evaluate(x_test, y_test, verbose=0)\n",
    "    #print('Student test loss: '  + str(score))\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1024])\n",
      "tensor([[0.0281, 0.0180, 0.0306,  ..., 0.0311, 0.0323, 0.0307],\n",
      "        [0.0376, 0.0267, 0.0293,  ..., 0.0250, 0.0251, 0.0296],\n",
      "        [0.0344, 0.0360, 0.0278,  ..., 0.0272, 0.0277, 0.0373],\n",
      "        [0.0358, 0.0309, 0.0307,  ..., 0.0341, 0.0362, 0.0355]])\n",
      "torch.Size([4, 1024])\n",
      "tensor([[0.0275, 0.0311, 0.0335,  ..., 0.0392, 0.0358, 0.0284],\n",
      "        [0.0417, 0.0398, 0.0382,  ..., 0.0369, 0.0415, 0.0331],\n",
      "        [0.0202, 0.0169, 0.0289,  ..., 0.0372, 0.0257, 0.0403],\n",
      "        [0.0257, 0.0245, 0.0465,  ..., 0.0305, 0.0282, 0.0244]])\n",
      "tensor(6.9508e-05)\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# try to understand how attention works\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "def attention(x):\n",
    "\n",
    "    return F.normalize(x.pow(2).mean(1).view(x.size(0), -1))\n",
    "\n",
    "def attention_diff(x, y):\n",
    "\n",
    "    return (attention(x) - attention(y)).pow(2).mean()\n",
    "\n",
    "x1 = torch.rand(4,32,32,32)\n",
    "y1 = attention(x1)\n",
    "print(str(y1.shape))\n",
    "print(str(y1))\n",
    "\n",
    "x2 = torch.rand(4,16,32,32)\n",
    "y2 = attention(x2)\n",
    "print(str(y2.shape))\n",
    "print(str(y2))\n",
    "\n",
    "y3 = attention_diff(x1,x2)\n",
    "print(str(y3))\n",
    "print(str(y3.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: [[0.5376377  0.6644214  0.44686377 0.47982714 0.09471644 0.07561981\n",
      "  0.1278151  0.16875194 0.5702069  0.0444722  0.629132   0.29709363\n",
      "  0.17219967 0.404269   0.29299808 0.32093096 0.9797734  0.8917266\n",
      "  0.72876054 0.93462974]\n",
      " [0.38360593 0.501185   0.52935904 0.7902392  0.18214895 0.68397456\n",
      "  0.00694319 0.05212032 0.44401866 0.06166412 0.02371873 0.08335436\n",
      "  0.552466   0.73791784 0.1474733  0.33985618 0.89610565 0.8512594\n",
      "  0.01452939 0.3812614 ]]\n",
      "\n",
      "b [[0.5376377  0.6644214  0.44686377 0.47982714 0.09471644 0.07561981\n",
      "  0.1278151  0.16875194 0.5702069  0.0444722 ]\n",
      " [0.38360593 0.501185   0.52935904 0.7902392  0.18214895 0.68397456\n",
      "  0.00694319 0.05212032 0.44401866 0.06166412]]\n",
      "\n",
      "c [[0.629132   0.29709363 0.17219967 0.404269   0.29299808 0.32093096\n",
      "  0.9797734  0.8917266  0.72876054 0.93462974]\n",
      " [0.02371873 0.08335436 0.552466   0.73791784 0.1474733  0.33985618\n",
      "  0.89610565 0.8512594  0.01452939 0.3812614 ]]\n",
      "\n",
      "d [[0.44686377 0.47982714]\n",
      " [0.52935904 0.7902392 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\na[0:5] takes elements from 0 to 4, so it takes the elements from the initial to the final excluded,\\nso if you want the thirs and fourth element you should use a[2:4]\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to understand how to get data from a tensor\n",
    "'''\n",
    "a[0:5] takes elements from 0 to 4, so it takes the elements from the initial to the final excluded,\n",
    "so if you want the thirs and fourth element you should use a[2:4]\n",
    "'''\n",
    "\n",
    "from keras.layers import Lambda\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "val = np.random.random((2, 20))\n",
    "a = K.variable(value=val)\n",
    "b = a[:,0:10]\n",
    "c = a[:,10:20]\n",
    "d = a[:,2:4]\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "                init = tf.global_variables_initializer()\n",
    "                sess.run(init)\n",
    "                print('a: ' + str(a.eval()))\n",
    "                print()\n",
    "                print('b ' + str(b.eval()))\n",
    "                print()\n",
    "                print('c ' + str(c.eval()))\n",
    "                print()\n",
    "                print('d ' + str(d.eval()))\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_gpuenv",
   "language": "python",
   "name": "tensorflow_gpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
