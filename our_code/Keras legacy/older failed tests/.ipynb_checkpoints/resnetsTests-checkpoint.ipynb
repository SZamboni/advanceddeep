{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 1 summary\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       BatchNorm2d-1           [-1, 16, 32, 32]              32\n",
      "              ReLU-2           [-1, 16, 32, 32]               0\n",
      "            Conv2d-3           [-1, 32, 32, 32]           4,608\n",
      "       BatchNorm2d-4           [-1, 32, 32, 32]              64\n",
      "              ReLU-5           [-1, 32, 32, 32]               0\n",
      "            Conv2d-6           [-1, 32, 32, 32]           9,216\n",
      "            Conv2d-7           [-1, 32, 32, 32]             512\n",
      "        BasicBlock-8           [-1, 32, 32, 32]               0\n",
      "       BatchNorm2d-9           [-1, 32, 32, 32]              64\n",
      "             ReLU-10           [-1, 32, 32, 32]               0\n",
      "           Conv2d-11           [-1, 32, 32, 32]           9,216\n",
      "      BatchNorm2d-12           [-1, 32, 32, 32]              64\n",
      "             ReLU-13           [-1, 32, 32, 32]               0\n",
      "           Conv2d-14           [-1, 32, 32, 32]           9,216\n",
      "       BasicBlock-15           [-1, 32, 32, 32]               0\n",
      "================================================================\n",
      "Total params: 32,992\n",
      "Trainable params: 32,992\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 3.50\n",
      "Params size (MB): 0.13\n",
      "Estimated Total Size (MB): 3.69\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "Block 2 summary\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       BatchNorm2d-1           [-1, 32, 32, 32]              64\n",
      "              ReLU-2           [-1, 32, 32, 32]               0\n",
      "            Conv2d-3           [-1, 64, 16, 16]          18,432\n",
      "       BatchNorm2d-4           [-1, 64, 16, 16]             128\n",
      "              ReLU-5           [-1, 64, 16, 16]               0\n",
      "            Conv2d-6           [-1, 64, 16, 16]          36,864\n",
      "            Conv2d-7           [-1, 64, 16, 16]           2,048\n",
      "        BasicBlock-8           [-1, 64, 16, 16]               0\n",
      "       BatchNorm2d-9           [-1, 64, 16, 16]             128\n",
      "             ReLU-10           [-1, 64, 16, 16]               0\n",
      "           Conv2d-11           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-12           [-1, 64, 16, 16]             128\n",
      "             ReLU-13           [-1, 64, 16, 16]               0\n",
      "           Conv2d-14           [-1, 64, 16, 16]          36,864\n",
      "       BasicBlock-15           [-1, 64, 16, 16]               0\n",
      "================================================================\n",
      "Total params: 131,520\n",
      "Trainable params: 131,520\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 2.12\n",
      "Params size (MB): 0.50\n",
      "Estimated Total Size (MB): 2.75\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "Block 3 summary\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       BatchNorm2d-1           [-1, 64, 32, 32]             128\n",
      "              ReLU-2           [-1, 64, 32, 32]               0\n",
      "            Conv2d-3          [-1, 128, 16, 16]          73,728\n",
      "       BatchNorm2d-4          [-1, 128, 16, 16]             256\n",
      "              ReLU-5          [-1, 128, 16, 16]               0\n",
      "            Conv2d-6          [-1, 128, 16, 16]         147,456\n",
      "            Conv2d-7          [-1, 128, 16, 16]           8,192\n",
      "        BasicBlock-8          [-1, 128, 16, 16]               0\n",
      "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
      "             ReLU-10          [-1, 128, 16, 16]               0\n",
      "           Conv2d-11          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
      "             ReLU-13          [-1, 128, 16, 16]               0\n",
      "           Conv2d-14          [-1, 128, 16, 16]         147,456\n",
      "       BasicBlock-15          [-1, 128, 16, 16]               0\n",
      "================================================================\n",
      "Total params: 525,184\n",
      "Trainable params: 525,184\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 4.25\n",
      "Params size (MB): 2.00\n",
      "Estimated Total Size (MB): 6.50\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             432\n",
      "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
      "              ReLU-3           [-1, 16, 32, 32]               0\n",
      "            Conv2d-4           [-1, 32, 32, 32]           4,608\n",
      "       BatchNorm2d-5           [-1, 32, 32, 32]              64\n",
      "              ReLU-6           [-1, 32, 32, 32]               0\n",
      "            Conv2d-7           [-1, 32, 32, 32]           9,216\n",
      "            Conv2d-8           [-1, 32, 32, 32]             512\n",
      "        BasicBlock-9           [-1, 32, 32, 32]               0\n",
      "      BatchNorm2d-10           [-1, 32, 32, 32]              64\n",
      "             ReLU-11           [-1, 32, 32, 32]               0\n",
      "           Conv2d-12           [-1, 32, 32, 32]           9,216\n",
      "      BatchNorm2d-13           [-1, 32, 32, 32]              64\n",
      "             ReLU-14           [-1, 32, 32, 32]               0\n",
      "           Conv2d-15           [-1, 32, 32, 32]           9,216\n",
      "       BasicBlock-16           [-1, 32, 32, 32]               0\n",
      "     NetworkBlock-17           [-1, 32, 32, 32]               0\n",
      "      BatchNorm2d-18           [-1, 32, 32, 32]              64\n",
      "             ReLU-19           [-1, 32, 32, 32]               0\n",
      "           Conv2d-20           [-1, 64, 16, 16]          18,432\n",
      "      BatchNorm2d-21           [-1, 64, 16, 16]             128\n",
      "             ReLU-22           [-1, 64, 16, 16]               0\n",
      "           Conv2d-23           [-1, 64, 16, 16]          36,864\n",
      "           Conv2d-24           [-1, 64, 16, 16]           2,048\n",
      "       BasicBlock-25           [-1, 64, 16, 16]               0\n",
      "      BatchNorm2d-26           [-1, 64, 16, 16]             128\n",
      "             ReLU-27           [-1, 64, 16, 16]               0\n",
      "           Conv2d-28           [-1, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-29           [-1, 64, 16, 16]             128\n",
      "             ReLU-30           [-1, 64, 16, 16]               0\n",
      "           Conv2d-31           [-1, 64, 16, 16]          36,864\n",
      "       BasicBlock-32           [-1, 64, 16, 16]               0\n",
      "     NetworkBlock-33           [-1, 64, 16, 16]               0\n",
      "      BatchNorm2d-34           [-1, 64, 16, 16]             128\n",
      "             ReLU-35           [-1, 64, 16, 16]               0\n",
      "           Conv2d-36            [-1, 128, 8, 8]          73,728\n",
      "      BatchNorm2d-37            [-1, 128, 8, 8]             256\n",
      "             ReLU-38            [-1, 128, 8, 8]               0\n",
      "           Conv2d-39            [-1, 128, 8, 8]         147,456\n",
      "           Conv2d-40            [-1, 128, 8, 8]           8,192\n",
      "       BasicBlock-41            [-1, 128, 8, 8]               0\n",
      "      BatchNorm2d-42            [-1, 128, 8, 8]             256\n",
      "             ReLU-43            [-1, 128, 8, 8]               0\n",
      "           Conv2d-44            [-1, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-45            [-1, 128, 8, 8]             256\n",
      "             ReLU-46            [-1, 128, 8, 8]               0\n",
      "           Conv2d-47            [-1, 128, 8, 8]         147,456\n",
      "       BasicBlock-48            [-1, 128, 8, 8]               0\n",
      "     NetworkBlock-49            [-1, 128, 8, 8]               0\n",
      "      BatchNorm2d-50            [-1, 128, 8, 8]             256\n",
      "             ReLU-51            [-1, 128, 8, 8]               0\n",
      "           Linear-52                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 691,674\n",
      "Trainable params: 691,674\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 7.38\n",
      "Params size (MB): 2.64\n",
      "Estimated Total Size (MB): 10.03\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# their resnet\n",
    "\"\"\"\n",
    "Code adapted from https://github.com/xternalz/WideResNet-pytorch\n",
    "Modifications = return activations for use in attention transfer,\n",
    "as done before e.g in https://github.com/BayesWatch/pytorch-moonshine\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        self.droprate = dropRate\n",
    "        self.equalInOut = (in_planes == out_planes)\n",
    "        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
    "                               padding=0, bias=False) or None\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.equalInOut:\n",
    "            x = self.relu1(self.bn1(x))\n",
    "        else:\n",
    "            out = self.relu1(self.bn1(x))\n",
    "        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n",
    "        if self.droprate > 0:\n",
    "            out = F.dropout(out, p=self.droprate, training=self.training)\n",
    "        out = self.conv2(out)\n",
    "        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n",
    "\n",
    "class NetworkBlock(nn.Module):\n",
    "    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n",
    "        super(NetworkBlock, self).__init__()\n",
    "        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n",
    "\n",
    "    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n",
    "        layers = []\n",
    "        for i in range(int(nb_layers)):\n",
    "            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n",
    "        super(WideResNet, self).__init__()\n",
    "        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n",
    "        assert((depth - 4) % 6 == 0)\n",
    "        n = (depth - 4) / 6\n",
    "        block = BasicBlock\n",
    "        # 1st conv before any network block\n",
    "        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n",
    "                               padding=1, bias=False)\n",
    "        # 1st block\n",
    "        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n",
    "        # 2nd block\n",
    "        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n",
    "        # 3rd block\n",
    "        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n",
    "        # global average pooling and classifier\n",
    "        self.bn1 = nn.BatchNorm2d(nChannels[3])\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc = nn.Linear(nChannels[3], num_classes)\n",
    "        self.nChannels = nChannels[3]\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.block1(out)\n",
    "        activation1 = out\n",
    "        out = self.block2(out)\n",
    "        activation2 = out\n",
    "        out = self.block3(out)\n",
    "        activation3 = out\n",
    "        out = self.relu(self.bn1(out))\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(-1, self.nChannels)\n",
    "        return self.fc(out), activation1, activation2, activation3\n",
    "    \n",
    "    def printBlock(self):\n",
    "        print('Block 1 summary')\n",
    "        print(summary(self.block1,(16,32,32)))\n",
    "        print('Block 2 summary')\n",
    "        print(summary(self.block2,(32,32,32)))\n",
    "        print('Block 3 summary')\n",
    "        print(summary(self.block3,(64,32,32)))\n",
    "    \n",
    "\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "#model = WideResNet(depth=16, num_classes=10, widen_factor=2, dropRate=0.0).to(device)\n",
    "#summary(model, input_size=(3, 32, 32))\n",
    "    \n",
    "    \n",
    "#x = torch.FloatTensor(64, 3, 32, 32).uniform_(0, 1)\n",
    "#model = WideResNet(depth=16, num_classes=10, widen_factor=2, dropRate=0.0)\n",
    "#print(summary(model, input_size=(3, 32, 32)))\n",
    "\n",
    "def main():\n",
    "    import random\n",
    "    import time\n",
    "    from torchsummary import summary\n",
    "\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    device_cpu = torch.device(\"cpu\")\n",
    "    #x = torch.FloatTensor(64, 3, 32, 32).uniform_(0, 1)\n",
    "    #x = x.to(device)\n",
    "\n",
    "    ### WideResNets\n",
    "    # Notation: W-depth-widening_factor\n",
    "    #model = WideResNet(depth=16, num_classes=10, widen_factor=1, dropRate=0.0)\n",
    "    model = WideResNet(depth=16, num_classes=10, widen_factor=2, dropRate=0.0)\n",
    "    #model = WideResNet(depth=16, num_classes=10, widen_factor=8, dropRate=0.0)\n",
    "    #model = WideResNet(depth=16, num_classes=10, widen_factor=10, dropRate=0.0)\n",
    "    #model = WideResNet(depth=22, num_classes=10, widen_factor=8, dropRate=0.0)\n",
    "    #model = WideResNet(depth=34, num_classes=10, widen_factor=2, dropRate=0.0)\n",
    "    #model = WideResNet(depth=40, num_classes=10, widen_factor=10, dropRate=0.0)\n",
    "    #model = WideResNet(depth=40, num_classes=10, widen_factor=1, dropRate=0.0)\n",
    "    #model = WideResNet(depth=40, num_classes=10, widen_factor=2, dropRate=0.0)\n",
    "    ###model = WideResNet(depth=50, num_classes=10, widen_factor=2, dropRate=0.0)\n",
    "    #model = model.to(device)\n",
    "    #t0 = time.time()\n",
    "    #output, *act = model(x)\n",
    "    #print(\"Time taken for forward pass: {} s\".format(time.time() - t0))\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.printBlock()\n",
    "    \n",
    "    #print(\"\\nOUTPUT SHPAE: \", output.shape)\n",
    "\n",
    "\n",
    "    print(summary(model, input_size=(3, 32, 32)))\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:52: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), padding=\"same\", strides=(1, 1), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:61: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), padding=\"same\", strides=(1, 1), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:81: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:89: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:52: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", strides=(2, 2), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First activation summary\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 32, 32, 16)   432         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 32, 32, 16)   64          conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 32, 32, 16)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 32, 32, 16)   2304        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 32, 32, 16)   64          conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 32, 32, 16)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 32, 32, 16)   2304        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 32, 32, 16)   256         activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 32, 32, 16)   0           conv2d_78[0][0]                  \n",
      "                                                                 conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 32, 32, 16)   64          add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 32, 32, 16)   0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 32, 32, 16)   2304        activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 32, 32, 16)   64          conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 32, 32, 16)   0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 32, 32, 16)   2304        activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 32, 32, 16)   0           add_29[0][0]                     \n",
      "                                                                 conv2d_81[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 10,160\n",
      "Trainable params: 10,032\n",
      "Non-trainable params: 128\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:61: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), padding=\"same\", strides=(2, 2), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:104: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:112: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second activation summary\n",
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 32, 32, 16)   432         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 32, 32, 16)   64          conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 32, 32, 16)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 32, 32, 16)   2304        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 32, 32, 16)   64          conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 32, 32, 16)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 32, 32, 16)   2304        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 32, 32, 16)   256         activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 32, 32, 16)   0           conv2d_78[0][0]                  \n",
      "                                                                 conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 32, 32, 16)   64          add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 32, 32, 16)   0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 32, 32, 16)   2304        activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 32, 32, 16)   64          conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 32, 32, 16)   0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 32, 32, 16)   2304        activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 32, 32, 16)   0           add_29[0][0]                     \n",
      "                                                                 conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 32, 32, 16)   64          add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 32, 32, 16)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 16, 16, 32)   4608        activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 16, 16, 32)   128         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 16, 16, 32)   0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 16, 16, 32)   9216        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 16, 16, 32)   512         activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 16, 16, 32)   0           conv2d_83[0][0]                  \n",
      "                                                                 conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 16, 16, 32)   128         add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 16, 16, 32)   0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 16, 16, 32)   9216        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 16, 16, 32)   128         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 16, 16, 32)   0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 16, 16, 32)   9216        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 16, 16, 32)   0           add_31[0][0]                     \n",
      "                                                                 conv2d_86[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 43,376\n",
      "Trainable params: 43,024\n",
      "Non-trainable params: 352\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:52: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", strides=(2, 2), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:61: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), padding=\"same\", strides=(2, 2), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:127: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Third activation summary\n",
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 32, 32, 16)   432         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 32, 32, 16)   64          conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 32, 32, 16)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 32, 32, 16)   2304        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 32, 32, 16)   64          conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 32, 32, 16)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 32, 32, 16)   2304        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 32, 32, 16)   256         activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 32, 32, 16)   0           conv2d_78[0][0]                  \n",
      "                                                                 conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 32, 32, 16)   64          add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 32, 32, 16)   0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 32, 32, 16)   2304        activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 32, 32, 16)   64          conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 32, 32, 16)   0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 32, 32, 16)   2304        activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 32, 32, 16)   0           add_29[0][0]                     \n",
      "                                                                 conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 32, 32, 16)   64          add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 32, 32, 16)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 16, 16, 32)   4608        activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 16, 16, 32)   128         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 16, 16, 32)   0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 16, 16, 32)   9216        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 16, 16, 32)   512         activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 16, 16, 32)   0           conv2d_83[0][0]                  \n",
      "                                                                 conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 16, 16, 32)   128         add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 16, 16, 32)   0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 16, 16, 32)   9216        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 16, 16, 32)   128         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 16, 16, 32)   0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 16, 16, 32)   9216        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 16, 16, 32)   0           add_31[0][0]                     \n",
      "                                                                 conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 16, 16, 32)   128         add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 16, 16, 32)   0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 64)     18432       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 8, 8, 64)     256         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 8, 8, 64)     0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 64)     36864       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 64)     2048        activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 8, 8, 64)     0           conv2d_88[0][0]                  \n",
      "                                                                 conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 64)     256         add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 64)     0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 64)     36864       activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 8, 8, 64)     256         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 8, 64)     0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 64)     36864       activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 8, 8, 64)     0           add_33[0][0]                     \n",
      "                                                                 conv2d_91[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 175,344\n",
      "Trainable params: 174,544\n",
      "Non-trainable params: 800\n",
      "__________________________________________________________________________________________________\n",
      "Wide Residual Network-16-1 created.\n",
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 32, 32, 16)   432         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 32, 32, 16)   64          conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 32, 32, 16)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 32, 32, 16)   2304        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 32, 32, 16)   64          conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 32, 32, 16)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 32, 32, 16)   2304        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 32, 32, 16)   256         activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 32, 32, 16)   0           conv2d_78[0][0]                  \n",
      "                                                                 conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 32, 32, 16)   64          add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 32, 32, 16)   0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 32, 32, 16)   2304        activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 32, 32, 16)   64          conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 32, 32, 16)   0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 32, 32, 16)   2304        activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 32, 32, 16)   0           add_29[0][0]                     \n",
      "                                                                 conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 32, 32, 16)   64          add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 32, 32, 16)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 16, 16, 32)   4608        activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 16, 16, 32)   128         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 16, 16, 32)   0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 16, 16, 32)   9216        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 16, 16, 32)   512         activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 16, 16, 32)   0           conv2d_83[0][0]                  \n",
      "                                                                 conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 16, 16, 32)   128         add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 16, 16, 32)   0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 16, 16, 32)   9216        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 16, 16, 32)   128         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 16, 16, 32)   0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 16, 16, 32)   9216        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 16, 16, 32)   0           add_31[0][0]                     \n",
      "                                                                 conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 16, 16, 32)   128         add_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 16, 16, 32)   0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 64)     18432       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 8, 8, 64)     256         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 8, 8, 64)     0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 64)     36864       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 64)     2048        activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_33 (Add)                    (None, 8, 8, 64)     0           conv2d_88[0][0]                  \n",
      "                                                                 conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 64)     256         add_33[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 64)     0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 64)     36864       activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 8, 8, 64)     256         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 8, 64)     0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 64)     36864       activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_34 (Add)                    (None, 8, 8, 64)     0           add_33[0][0]                     \n",
      "                                                                 conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 8, 8, 64)     256         add_34[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 8, 8, 64)     0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 1, 1, 64)     0           activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 64)           0           average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 10)           650         flatten_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 176,250\n",
      "Trainable params: 175,322\n",
      "Non-trainable params: 928\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:135: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:212: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, activation=\"softmax\", kernel_regularizer=<keras.reg...)`\n"
     ]
    }
   ],
   "source": [
    "# keras resnet\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Add, Activation, Dropout, Flatten, Dense\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "#import wide_residual_network as wrn\n",
    "from keras.datasets import cifar10\n",
    "import keras.callbacks as callbacks\n",
    "import keras.utils.np_utils as kutils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "\n",
    "weight_decay = 0.0005\n",
    "\n",
    "def initial_conv(input):\n",
    "    x = Convolution2D(16, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(input)\n",
    "\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def expand_conv(init, base, k, strides=(1, 1)):\n",
    "    x = Convolution2D(base * k, (3, 3), padding='same', strides=strides, kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(init)\n",
    "\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Convolution2D(base * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    skip = Convolution2D(base * k, (1, 1), padding='same', strides=strides, kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(init)\n",
    "\n",
    "    m = Add()([x, skip])\n",
    "\n",
    "    return m\n",
    "\n",
    "\n",
    "def conv1_block(input, k=1, dropout=0.0):\n",
    "    init = input\n",
    "\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    m = Add()([init, x])\n",
    "    return m\n",
    "\n",
    "def conv2_block(input, k=1, dropout=0.0):\n",
    "    init = input\n",
    "\n",
    "    #channel_axis = 1 if K.image_dim_ordering() == \"th\" else -1\n",
    "    channel_axis = -1\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    m = Add()([init, x])\n",
    "    return m\n",
    "\n",
    "def conv3_block(input, k=1, dropout=0.0):\n",
    "    init = input\n",
    "\n",
    "    #channel_axis = 1 if K.image_dim_ordering() == \"th\" else -1\n",
    "    channel_axis = -1\n",
    "    \n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    m = Add()([init, x])\n",
    "    return m\n",
    "\n",
    "def create_wide_residual_network(input_dim, nb_classes=100, N=2, k=1, dropout=0.0, verbose=1):\n",
    "    \"\"\"\n",
    "    Creates a Wide Residual Network with specified parameters\n",
    "\n",
    "    :param input: Input Keras object\n",
    "    :param nb_classes: Number of output classes\n",
    "    :param N: Depth of the network. Compute N = (n - 4) / 6.\n",
    "              Example : For a depth of 16, n = 16, N = (16 - 4) / 6 = 2\n",
    "              Example2: For a depth of 28, n = 28, N = (28 - 4) / 6 = 4\n",
    "              Example3: For a depth of 40, n = 40, N = (40 - 4) / 6 = 6\n",
    "    :param k: Width of the network.\n",
    "    :param dropout: Adds dropout if value is greater than 0.0\n",
    "    :param verbose: Debug info to describe created WRN\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "\n",
    "    ip = Input(shape=input_dim)\n",
    "\n",
    "    x = initial_conv(ip)\n",
    "    nb_conv = 4\n",
    "\n",
    "    x = expand_conv(x, 16, k)\n",
    "    nb_conv += 2\n",
    "\n",
    "    for i in range(N - 1):\n",
    "        x = conv1_block(x, k, dropout)\n",
    "        nb_conv += 2\n",
    "\n",
    "    print('First activation summary')\n",
    "    out1 = x\n",
    "    a = Model(ip,out1)\n",
    "    a.summary()\n",
    "        \n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = expand_conv(x, 32, k, strides=(2, 2))\n",
    "    nb_conv += 2\n",
    "    \n",
    "    \n",
    "\n",
    "    for i in range(N - 1):\n",
    "        x = conv2_block(x, k, dropout)\n",
    "        nb_conv += 2\n",
    "        \n",
    "    print('Second activation summary')\n",
    "    out2 = x\n",
    "    b = Model(ip,out2)\n",
    "    b.summary()\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = expand_conv(x, 64, k, strides=(2, 2))\n",
    "    nb_conv += 2\n",
    "\n",
    "    for i in range(N - 1):\n",
    "        x = conv3_block(x, k, dropout)\n",
    "        nb_conv += 2\n",
    "    \n",
    "    print('Third activation summary')\n",
    "    out3 = x\n",
    "    c = Model(ip,out3)\n",
    "    c.summary()\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = AveragePooling2D((8, 8))(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(nb_classes, W_regularizer=l2(weight_decay), activation='softmax')(x)\n",
    "\n",
    "    model = Model(ip, [x,out1,out2,out3])\n",
    "\n",
    "    if verbose: print(\"Wide Residual Network-%d-%d created.\" % (nb_conv, k))\n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    \n",
    "    model = create_wide_residual_network\n",
    "    input_shape = (32,32,3)\n",
    "    model=create_wide_residual_network(input_shape, 10, N=2, k=1, dropout=0.)\n",
    "    model.summary()\n",
    "    \n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10 loaded\n",
      "CIFAR10 shape: (32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:77: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), padding=\"same\", strides=(1, 1), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:86: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:90: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), padding=\"same\", strides=(1, 1), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:106: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:114: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First activation summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:77: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", strides=(2, 2), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:86: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:90: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), padding=\"same\", strides=(2, 2), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:129: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:137: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:77: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", strides=(2, 2), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:86: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:90: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), padding=\"same\", strides=(2, 2), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second activation summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:152: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:160: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:231: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, activation=\"softmax\", kernel_regularizer=<keras.reg...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Third activation summary\n",
      "Wide Residual Network-16-1 created.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid argument \"metric\" passed to K.function with TensorFlow backend",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a3b5dd9967c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0mtrainNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-a3b5dd9967c9>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m     \u001b[0mtrainNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-a3b5dd9967c9>\u001b[0m in \u001b[0;36mtrainNetwork\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0mn_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m     print('predictions shape ' + str(predictions[0].shape) + ' ' + str(predictions[1].shape) +\n\u001b[1;32m    336\u001b[0m           ' ' + str(predictions[2].shape) + ' ' + str(predictions[3].shape))\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1456\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1457\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m         return training_arrays.predict_loop(self, f, ins,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_predict_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    376\u001b[0m                                                \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_updates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m                                                \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'predict_function'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m                                                **kwargs)\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[1;32m   3007\u001b[0m     return tf_keras_backend.function(inputs, outputs,\n\u001b[1;32m   3008\u001b[0m                                      \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3009\u001b[0;31m                                      **kwargs)\n\u001b[0m\u001b[1;32m   3010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, updates, name, **kwargs)\u001b[0m\n\u001b[1;32m   3476\u001b[0m         msg = ('Invalid argument \"%s\" passed to K.function with TensorFlow '\n\u001b[1;32m   3477\u001b[0m                'backend') % key\n\u001b[0;32m-> 3478\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3479\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mGraphExecutionFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid argument \"metric\" passed to K.function with TensorFlow backend"
     ]
    }
   ],
   "source": [
    "#train our new WResNet\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "from keras.losses import KLDivergence\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import keras\n",
    "from keract import get_activations\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Add, Activation, Dropout, Flatten, Dense\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "#import wide_residual_network as wrn\n",
    "from keras.datasets import cifar10\n",
    "import keras.callbacks as callbacks\n",
    "import keras.utils.np_utils as kutils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "weight_decay = 0.0005\n",
    "\n",
    "def initial_conv(input):\n",
    "    x = Convolution2D(16, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(input)\n",
    "\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def expand_conv(init, base, k, strides=(1, 1)):\n",
    "    x = Convolution2D(base * k, (3, 3), padding='same', strides=strides, kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(init)\n",
    "\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Convolution2D(base * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    skip = Convolution2D(base * k, (1, 1), padding='same', strides=strides, kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(init)\n",
    "\n",
    "    m = Add()([x, skip])\n",
    "\n",
    "    return m\n",
    "\n",
    "\n",
    "def conv1_block(input, k=1, dropout=0.0):\n",
    "    init = input\n",
    "\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    m = Add()([init, x])\n",
    "    return m\n",
    "\n",
    "def conv2_block(input, k=1, dropout=0.0):\n",
    "    init = input\n",
    "\n",
    "    #channel_axis = 1 if K.image_dim_ordering() == \"th\" else -1\n",
    "    channel_axis = -1\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    m = Add()([init, x])\n",
    "    return m\n",
    "\n",
    "def conv3_block(input, k=1, dropout=0.0):\n",
    "    init = input\n",
    "\n",
    "    #channel_axis = 1 if K.image_dim_ordering() == \"th\" else -1\n",
    "    channel_axis = -1\n",
    "    \n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    m = Add()([init, x])\n",
    "    return m\n",
    "\n",
    "def create_wide_residual_network(input_dim, nb_classes=100, N=2, k=1, dropout=0.0, verbose=1):\n",
    "    \"\"\"\n",
    "    Creates a Wide Residual Network with specified parameters\n",
    "\n",
    "    :param input: Input Keras object\n",
    "    :param nb_classes: Number of output classes\n",
    "    :param N: Depth of the network. Compute N = (n - 4) / 6.\n",
    "              Example : For a depth of 16, n = 16, N = (16 - 4) / 6 = 2\n",
    "              Example2: For a depth of 28, n = 28, N = (28 - 4) / 6 = 4\n",
    "              Example3: For a depth of 40, n = 40, N = (40 - 4) / 6 = 6\n",
    "    :param k: Width of the network.\n",
    "    :param dropout: Adds dropout if value is greater than 0.0\n",
    "    :param verbose: Debug info to describe created WRN\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "\n",
    "    ip = Input(shape=input_dim)\n",
    "\n",
    "    x = initial_conv(ip)\n",
    "    nb_conv = 4\n",
    "\n",
    "    x = expand_conv(x, 16, k)\n",
    "    nb_conv += 2\n",
    "\n",
    "    for i in range(N - 1):\n",
    "        x = conv1_block(x, k, dropout)\n",
    "        nb_conv += 2\n",
    "\n",
    "    print('First activation summary')\n",
    "    out1 = x\n",
    "        \n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = expand_conv(x, 32, k, strides=(2, 2))\n",
    "    nb_conv += 2\n",
    "    \n",
    "    \n",
    "\n",
    "    for i in range(N - 1):\n",
    "        x = conv2_block(x, k, dropout)\n",
    "        nb_conv += 2\n",
    "        \n",
    "    print('Second activation summary')\n",
    "    out2 = x\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = expand_conv(x, 64, k, strides=(2, 2))\n",
    "    nb_conv += 2\n",
    "\n",
    "    for i in range(N - 1):\n",
    "        x = conv3_block(x, k, dropout)\n",
    "        nb_conv += 2\n",
    "    \n",
    "    print('Third activation summary')\n",
    "    out3 = x\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = AveragePooling2D((8, 8))(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(nb_classes, W_regularizer=l2(weight_decay), activation='softmax')(x)\n",
    "\n",
    "    model = Model(ip, [x,out1,out2,out3])\n",
    "\n",
    "    if verbose: print(\"Wide Residual Network-%d-%d created.\" % (nb_conv, k))\n",
    "    return model\n",
    "\n",
    "\n",
    "'''\n",
    "Function that returns the trainand test data of the CIFAR10 already preprocessed\n",
    "'''\n",
    "def getCIFAR10():\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = 32, 32\n",
    "    num_classes = 10\n",
    "\n",
    "    # the data, split between train and test sets\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    \n",
    "    # format of the tensor\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
    "        x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
    "        input_shape = (3, img_rows, img_cols)\n",
    "    else:\n",
    "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "        input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "    # convert in to float the images\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    \n",
    "    # new normalization with z-score\n",
    "    mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "    std = np.std(x_train,axis=(0,1,2,3))\n",
    "    x_train = (x_train-mean)/(std+1e-7)\n",
    "    x_test = (x_test-mean)/(std+1e-7)\n",
    "    \n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    print('CIFAR10 loaded')\n",
    "    return x_train,y_train,x_test,y_test\n",
    "\n",
    "'''\n",
    "Small function that returns the shape of the CIFAR10 images\n",
    "'''\n",
    "def getCIFAR10InputShape():\n",
    "    img_rows, img_cols = 32, 32\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (3, img_rows, img_cols)\n",
    "    else:\n",
    "        input_shape = (img_rows, img_cols, 3)\n",
    "        \n",
    "    return input_shape\n",
    "\n",
    "def getNetwork(input_shape):\n",
    "    model=create_wide_residual_network(input_shape, 10, N=2, k=1, dropout=0.)\n",
    "    plot_model(model, \"WRN-16-1.png\", show_shapes=True, show_layer_names=True)\n",
    "    return model;\n",
    "\n",
    "def myLoss(y_true,y_pred):\n",
    "    \n",
    "    real_pred = y_pred\n",
    "    real_true = y_true\n",
    "    \n",
    "    loss = keras.losses.categorical_crossentropy(real_true,real_pred)\n",
    "    \n",
    "    return loss;\n",
    "\n",
    "def useless_loss(y_true,y_pred):\n",
    "    \n",
    "    zer = K.zeros(1)\n",
    "    \n",
    "    return zer\n",
    "\n",
    "def myaccuracy(y_true, y_pred):\n",
    "    \n",
    "    real_pred = y_pred[0]\n",
    "    real_true = y_true[0]\n",
    "    \n",
    "    return keras.metrics.categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "'''\n",
    "Function to try to train the network on CIFAR10\n",
    "'''\n",
    "def trainNetwork(epochs):\n",
    "    \n",
    "    x_train,y_train,x_test,y_test = getCIFAR10()\n",
    "    \n",
    "    input_shape = getCIFAR10InputShape()\n",
    "    print('CIFAR10 shape: ' + str(input_shape))\n",
    "    \n",
    "    model = getNetwork(input_shape)\n",
    "    \n",
    "    model.compile(loss=[myLoss, useless_loss, useless_loss,useless_loss],\n",
    "              optimizer='adam')\n",
    "    \n",
    "    batch_size = 128\n",
    "    n_batches = math.floor( x_train.shape[0] / batch_size)\n",
    "    \n",
    "    predictions = model.predict(x_train[0:1])\n",
    "    print('predictions shape ' + str(predictions[0].shape) + ' ' + str(predictions[1].shape) +\n",
    "          ' ' + str(predictions[2].shape) + ' ' + str(predictions[3].shape))\n",
    "\n",
    "    for e in range(epochs):\n",
    "    \n",
    "        for i in range(0,n_batches):\n",
    "            imgs = x_train[i*batch_size:(i+1)*batch_size]\n",
    "            labels = y_train[i*batch_size:(i+1)*batch_size]\n",
    "            \n",
    "            tmp_labels1 = K.zeros((batch_size,32,32,16))\n",
    "            tmp_labels2 = K.zeros((batch_size,16,16,32))\n",
    "            tmp_labels3 = K.zeros((batch_size,8,8,64))\n",
    "            \n",
    "            loss = model.train_on_batch(imgs,[labels, tmp_labels1, tmp_labels2, tmp_labels3])\n",
    "            \n",
    "            print(\"Epoch: \" + str(e+1) + \" batch \" + str(i) + \" train loss: \" + str(loss))\n",
    "            \n",
    "        #score = model.evaluate(x_test, y_test, verbose=0)\n",
    "        print('After epoch ' + str(e+1) + ' test loss ' + str(score) + ' test accuracy ' + str(score))\n",
    "\n",
    "def main():\n",
    "    trainNetwork(5)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10 loaded\n",
      "CIFAR10 shape: (32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:77: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), padding=\"same\", strides=(1, 1), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:86: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:90: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), padding=\"same\", strides=(1, 1), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:106: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:114: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:77: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", strides=(2, 2), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First activation summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:86: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:90: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), padding=\"same\", strides=(2, 2), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:129: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:137: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second activation summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:77: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", strides=(2, 2), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:86: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:90: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), padding=\"same\", strides=(2, 2), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:152: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:160: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:231: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, activation=\"softmax\", kernel_regularizer=<keras.reg...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Third activation summary\n",
      "Wide Residual Network-16-1 created.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "50000/50000 [==============================] - 28s 568us/step - loss: 1.8117 - acc: 0.4312 - val_loss: 1.3165 - val_acc: 0.5843\n",
      "Epoch 2/2\n",
      "50000/50000 [==============================] - 26s 524us/step - loss: 1.1601 - acc: 0.6399 - val_loss: 1.0602 - val_acc: 0.6785\n",
      "Full model predictions:\n",
      "[[8.7697332e-04 4.2944841e-04 3.8611881e-02 4.5042118e-01 2.0880094e-02\n",
      "  3.0573282e-01 1.6604018e-01 1.6066436e-02 5.2239379e-04 4.1856553e-04]]\n",
      "Model 1 predictions:\n",
      "[array([[[[ 0.1077102 , -0.0100246 ,  0.1954115 , ...,  0.01236693,\n",
      "          -0.11393171,  0.00953884],\n",
      "         [ 0.08172166,  0.12524375,  0.15642695, ...,  0.07260023,\n",
      "          -0.04846612, -0.00792598],\n",
      "         [ 0.04368145,  0.08249444,  0.14672537, ...,  0.06307021,\n",
      "           0.0423757 ,  0.03603948],\n",
      "         ...,\n",
      "         [ 0.02156087,  0.02610946,  0.08266972, ...,  0.02305071,\n",
      "           0.05705534,  0.02804315],\n",
      "         [ 0.0058015 ,  0.06322838,  0.08621318, ...,  0.03126223,\n",
      "           0.08345835,  0.08404981],\n",
      "         [ 0.01454124, -0.02253578,  0.12709   , ...,  0.02832267,\n",
      "           0.05062149,  0.10027261]],\n",
      "\n",
      "        [[ 0.14359112,  0.02728691,  0.2556378 , ...,  0.05269459,\n",
      "          -0.15831088,  0.00416378],\n",
      "         [ 0.05354233,  0.17415388,  0.31480235, ...,  0.12668741,\n",
      "          -0.07430526, -0.0842368 ],\n",
      "         [-0.04269435,  0.11069962,  0.2960971 , ...,  0.12615946,\n",
      "           0.03990491, -0.02341262],\n",
      "         ...,\n",
      "         [ 0.06584671,  0.10372586,  0.22784916, ...,  0.05182461,\n",
      "          -0.00501444, -0.09241985],\n",
      "         [ 0.06484863,  0.05984255,  0.33874643, ...,  0.04971189,\n",
      "           0.0301318 , -0.07892036],\n",
      "         [ 0.04561222,  0.02459383,  0.21840735, ...,  0.03390674,\n",
      "          -0.04402334, -0.0473354 ]],\n",
      "\n",
      "        [[ 0.12916715,  0.05101756,  0.2099038 , ...,  0.0207577 ,\n",
      "          -0.13035442,  0.04268897],\n",
      "         [-0.01233217,  0.10440992,  0.25050724, ...,  0.15073764,\n",
      "          -0.05811176, -0.08360763],\n",
      "         [-0.13245508, -0.01757452,  0.2974721 , ...,  0.1544667 ,\n",
      "           0.06756169, -0.00637589],\n",
      "         ...,\n",
      "         [-0.0178259 ,  0.06839019,  0.25616413, ...,  0.0619931 ,\n",
      "          -0.01718489, -0.0892801 ],\n",
      "         [-0.02817784,  0.03224572,  0.38915727, ...,  0.07261243,\n",
      "          -0.09032727, -0.00069395],\n",
      "         [ 0.11469173, -0.13065447,  0.26317853, ...,  0.04263958,\n",
      "          -0.12283497, -0.04277617]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.21740803,  0.02291872,  0.22447804, ...,  0.08160055,\n",
      "           0.07150854,  0.11015946],\n",
      "         [ 0.13492832,  0.1096016 ,  0.22051987, ...,  0.03617984,\n",
      "           0.02928401, -0.08767927],\n",
      "         [-0.11599338, -0.07628276,  0.20154282, ...,  0.04577872,\n",
      "           0.03176962, -0.00812069],\n",
      "         ...,\n",
      "         [-0.07486206,  0.30873558,  0.28933284, ..., -0.01516294,\n",
      "           0.13367194,  0.27588835],\n",
      "         [ 0.34355772,  0.16399652,  0.2564737 , ...,  0.10023098,\n",
      "          -0.0754087 , -0.11857357],\n",
      "         [ 0.06558803, -0.27295747,  0.2459062 , ..., -0.03763386,\n",
      "          -0.12362836, -0.01381516]],\n",
      "\n",
      "        [[-0.20855866,  0.06939164,  0.268327  , ...,  0.0611062 ,\n",
      "           0.03497389,  0.10951139],\n",
      "         [ 0.10129655,  0.07508785,  0.29985923, ...,  0.06076252,\n",
      "          -0.00864772, -0.12705031],\n",
      "         [-0.15856676, -0.06236884,  0.23379345, ...,  0.0598437 ,\n",
      "          -0.05493919,  0.00062798],\n",
      "         ...,\n",
      "         [-0.14751562,  0.1598786 ,  0.34143868, ..., -0.00382581,\n",
      "           0.11978852,  0.20298764],\n",
      "         [ 0.3085264 ,  0.04229189,  0.28519446, ...,  0.04093741,\n",
      "          -0.02022583, -0.1368706 ],\n",
      "         [ 0.03555762, -0.2562635 ,  0.23554045, ..., -0.09154167,\n",
      "          -0.18965146,  0.06449482]],\n",
      "\n",
      "        [[-0.05236304, -0.02230347,  0.10309476, ...,  0.01646614,\n",
      "          -0.01916707,  0.10278942],\n",
      "         [ 0.18055263, -0.13188682,  0.09339136, ...,  0.0416024 ,\n",
      "          -0.03050783, -0.09400836],\n",
      "         [ 0.06011801, -0.19488868,  0.03682242, ..., -0.0107379 ,\n",
      "          -0.09383644,  0.01926827],\n",
      "         ...,\n",
      "         [ 0.07926306,  0.03218197,  0.07258995, ..., -0.02320935,\n",
      "           0.04378701,  0.09175994],\n",
      "         [ 0.26655602, -0.03136839,  0.02249858, ...,  0.01825959,\n",
      "           0.03791808, -0.0984347 ],\n",
      "         [ 0.05056704, -0.15196459,  0.06244878, ..., -0.0595407 ,\n",
      "          -0.14373352, -0.00058596]]]], dtype=float32), array([[8.7697332e-04, 4.2944841e-04, 3.8611881e-02, 4.5042118e-01,\n",
      "        2.0880094e-02, 3.0573282e-01, 1.6604018e-01, 1.6066436e-02,\n",
      "        5.2239379e-04, 4.1856553e-04]], dtype=float32)]\n",
      "Model 2 predictions:\n",
      "[array([[[[ 0.04499613, -0.09329911, -0.07687815, ..., -0.01827256,\n",
      "          -0.10452625, -0.10943296],\n",
      "         [ 0.07932431, -0.10901306, -0.09769101, ..., -0.020981  ,\n",
      "          -0.03486638, -0.18962768],\n",
      "         [ 0.02823123, -0.05808246, -0.07775456, ...,  0.00518544,\n",
      "          -0.00528577, -0.15983365],\n",
      "         ...,\n",
      "         [ 0.02501846, -0.02636192, -0.04008524, ..., -0.057181  ,\n",
      "          -0.06702162, -0.11482087],\n",
      "         [-0.04157179, -0.02395636,  0.01697347, ..., -0.02894613,\n",
      "          -0.03670406, -0.17669106],\n",
      "         [ 0.04134192, -0.0479678 , -0.03721321, ..., -0.03176997,\n",
      "          -0.0365469 , -0.09444311]],\n",
      "\n",
      "        [[ 0.09801704, -0.0439255 , -0.03163227, ...,  0.08297509,\n",
      "           0.00947041, -0.14207427],\n",
      "         [ 0.23977447, -0.05885196, -0.07199632, ...,  0.16733892,\n",
      "           0.04083898, -0.18202871],\n",
      "         [ 0.17019658, -0.05693593,  0.02251155, ...,  0.04449388,\n",
      "           0.03862832, -0.09582828],\n",
      "         ...,\n",
      "         [ 0.17172903, -0.03444555, -0.02425468, ...,  0.04422975,\n",
      "          -0.06805242, -0.05434521],\n",
      "         [ 0.07744948,  0.03102335,  0.01717276, ...,  0.05034667,\n",
      "          -0.08263436, -0.16340092],\n",
      "         [ 0.13214904, -0.06836674, -0.0732698 , ...,  0.02161725,\n",
      "          -0.12570299, -0.08514294]],\n",
      "\n",
      "        [[ 0.1155099 , -0.00976813, -0.08234286, ...,  0.10696341,\n",
      "           0.03420656, -0.13262148],\n",
      "         [ 0.23036724, -0.04364539, -0.04952006, ...,  0.13990363,\n",
      "           0.08692941, -0.1610149 ],\n",
      "         [ 0.1440825 , -0.02165721, -0.01511727, ...,  0.05226567,\n",
      "           0.03300398, -0.11935352],\n",
      "         ...,\n",
      "         [ 0.20726909, -0.05156705, -0.12754872, ...,  0.06496781,\n",
      "          -0.00099749, -0.11454569],\n",
      "         [ 0.0879515 ,  0.0057535 , -0.051241  , ...,  0.1011049 ,\n",
      "          -0.00210319, -0.23810166],\n",
      "         [ 0.07315798, -0.06420708, -0.08683097, ..., -0.00523532,\n",
      "          -0.0475774 , -0.14205629]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.09336908,  0.00911503, -0.05954523, ...,  0.05144339,\n",
      "          -0.0463973 , -0.08538508],\n",
      "         [ 0.19350538, -0.03669702,  0.00037868, ...,  0.03370673,\n",
      "           0.02655546, -0.08800319],\n",
      "         [ 0.17669329, -0.11376927,  0.05095736, ..., -0.01717819,\n",
      "          -0.07457064, -0.1276407 ],\n",
      "         ...,\n",
      "         [ 0.17163932, -0.02590678, -0.03625617, ..., -0.0165609 ,\n",
      "          -0.08581702, -0.07273226],\n",
      "         [ 0.11825635,  0.097964  , -0.03584409, ...,  0.04034448,\n",
      "          -0.05390862, -0.22585288],\n",
      "         [ 0.15611503, -0.04323181, -0.09986121, ..., -0.08486374,\n",
      "          -0.10263941, -0.14316462]],\n",
      "\n",
      "        [[ 0.06295566, -0.02813751, -0.06315102, ...,  0.07087608,\n",
      "          -0.05585407, -0.1300003 ],\n",
      "         [ 0.10201465, -0.0078175 , -0.02986298, ..., -0.02865925,\n",
      "          -0.09369046, -0.12875994],\n",
      "         [ 0.05641599,  0.02033586,  0.02565395, ..., -0.08605289,\n",
      "          -0.05016457, -0.17509353],\n",
      "         ...,\n",
      "         [ 0.04693253, -0.16652155,  0.10080378, ..., -0.18168256,\n",
      "          -0.11005058, -0.16211568],\n",
      "         [-0.00066876, -0.01881051,  0.07676543, ..., -0.02880011,\n",
      "          -0.0157691 , -0.25577182],\n",
      "         [ 0.02979669, -0.0727278 , -0.09869745, ..., -0.04129346,\n",
      "          -0.01056537, -0.17879039]],\n",
      "\n",
      "        [[ 0.03520253,  0.01784052, -0.01870925, ...,  0.08507822,\n",
      "          -0.02668649, -0.09017791],\n",
      "         [ 0.08953832,  0.01865297, -0.05193933, ...,  0.1017908 ,\n",
      "          -0.07040901, -0.06613588],\n",
      "         [ 0.04441911,  0.02271287, -0.06068942, ...,  0.03036665,\n",
      "          -0.13856226, -0.04479093],\n",
      "         ...,\n",
      "         [ 0.03819105, -0.04050358,  0.02736925, ...,  0.00027061,\n",
      "          -0.02476404, -0.08660381],\n",
      "         [ 0.05370134, -0.06613762,  0.04845493, ...,  0.12222707,\n",
      "           0.04236108, -0.12012304],\n",
      "         [-0.0392388 , -0.02177464,  0.02599532, ...,  0.02117959,\n",
      "          -0.1132298 , -0.02118443]]]], dtype=float32), array([[8.7697332e-04, 4.2944841e-04, 3.8611881e-02, 4.5042118e-01,\n",
      "        2.0880094e-02, 3.0573282e-01, 1.6604018e-01, 1.6066436e-02,\n",
      "        5.2239379e-04, 4.1856553e-04]], dtype=float32)]\n",
      "Model 3 predictions:\n",
      "[array([[[[-0.04798359,  0.00477439,  0.0115047 , ..., -0.08665685,\n",
      "          -0.01705454, -0.0335623 ],\n",
      "         [-0.09376918, -0.00306234,  0.00687713, ..., -0.14259568,\n",
      "          -0.05772263, -0.06135227],\n",
      "         [-0.09820592,  0.0037858 , -0.04272926, ..., -0.14102754,\n",
      "          -0.03053221, -0.03975317],\n",
      "         ...,\n",
      "         [-0.05796517,  0.0278128 , -0.06013803, ..., -0.06007094,\n",
      "           0.01985481,  0.02375805],\n",
      "         [-0.00940408,  0.046064  , -0.00126682, ..., -0.03593252,\n",
      "           0.00062595, -0.0069207 ],\n",
      "         [ 0.00121553,  0.0300904 ,  0.03369602, ..., -0.02368239,\n",
      "           0.0078823 , -0.01283222]],\n",
      "\n",
      "        [[-0.04122794,  0.0133206 , -0.00833568, ..., -0.09778947,\n",
      "          -0.01192842, -0.01355577],\n",
      "         [-0.09291823,  0.01521268, -0.02692017, ..., -0.15060928,\n",
      "          -0.01686741, -0.02847384],\n",
      "         [-0.10515716,  0.02296059, -0.08697367, ..., -0.14915332,\n",
      "           0.03083382,  0.00799485],\n",
      "         ...,\n",
      "         [-0.06869429,  0.01872372, -0.08642171, ..., -0.02056611,\n",
      "           0.02618706,  0.10054453],\n",
      "         [-0.02163216,  0.03536094, -0.01806319, ..., -0.0228421 ,\n",
      "          -0.02531727,  0.02034922],\n",
      "         [-0.00597279,  0.02492164,  0.03916574, ..., -0.02415696,\n",
      "           0.00858836, -0.018258  ]],\n",
      "\n",
      "        [[-0.02823277,  0.0144025 , -0.03636058, ..., -0.07738231,\n",
      "          -0.03077416, -0.02362664],\n",
      "         [-0.06691059,  0.01805214, -0.08384807, ..., -0.10278039,\n",
      "          -0.01580764, -0.02104556],\n",
      "         [-0.08084486,  0.02464454, -0.1504471 , ..., -0.0818856 ,\n",
      "           0.01895928,  0.05621154],\n",
      "         ...,\n",
      "         [-0.08945455,  0.01028499, -0.0916682 , ...,  0.02170091,\n",
      "           0.07227327,  0.12201238],\n",
      "         [-0.03955679,  0.01946384, -0.02055968, ..., -0.00640183,\n",
      "           0.03414702,  0.04510744],\n",
      "         [-0.02870413,  0.00974481,  0.0260735 , ..., -0.01412719,\n",
      "           0.01612759, -0.01504084]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.01282763, -0.00062948,  0.01679407, ...,  0.02279774,\n",
      "          -0.07479173,  0.0204234 ],\n",
      "         [-0.04746362, -0.0185356 , -0.00628999, ...,  0.04565024,\n",
      "          -0.09958093,  0.07731018],\n",
      "         [-0.0558654 , -0.02889911, -0.04669543, ...,  0.0733657 ,\n",
      "          -0.07382059,  0.12911722],\n",
      "         ...,\n",
      "         [-0.08562672, -0.03659363,  0.08838224, ...,  0.01795622,\n",
      "          -0.03597778,  0.01357675],\n",
      "         [-0.04496275, -0.03720937,  0.13025849, ..., -0.01558916,\n",
      "          -0.10481732, -0.08471611],\n",
      "         [-0.01981751, -0.02176494,  0.09305036, ..., -0.02267912,\n",
      "          -0.06700094, -0.02926053]],\n",
      "\n",
      "        [[ 0.01583256,  0.02098558,  0.01360365, ...,  0.01887926,\n",
      "          -0.04290124, -0.02186148],\n",
      "         [-0.00403784,  0.01242335,  0.0249965 , ...,  0.01762196,\n",
      "          -0.0599749 ,  0.01219928],\n",
      "         [-0.02941689,  0.01036881, -0.01808485, ...,  0.02441035,\n",
      "          -0.03808104, -0.01371181],\n",
      "         ...,\n",
      "         [-0.06976218, -0.01461501,  0.07540971, ...,  0.01884179,\n",
      "          -0.03408116, -0.07434006],\n",
      "         [-0.03709095, -0.01640501,  0.10349237, ...,  0.0158473 ,\n",
      "          -0.0860575 , -0.07400966],\n",
      "         [-0.01577515, -0.00832622,  0.05661298, ..., -0.00577754,\n",
      "          -0.07145671, -0.04672021]],\n",
      "\n",
      "        [[ 0.02928599,  0.03642901, -0.01453655, ...,  0.02027605,\n",
      "          -0.01104567, -0.01274845],\n",
      "         [ 0.02977882,  0.04486306,  0.00957829, ...,  0.01655599,\n",
      "           0.01753938, -0.00838142],\n",
      "         [ 0.00256789,  0.03285164, -0.02278005, ...,  0.02716325,\n",
      "           0.02974532, -0.00231869],\n",
      "         ...,\n",
      "         [-0.04504745,  0.00127464,  0.02041288, ...,  0.01570801,\n",
      "          -0.01531952, -0.09026383],\n",
      "         [-0.02234144, -0.0006446 ,  0.05932026, ...,  0.01990204,\n",
      "          -0.06066824, -0.09422973],\n",
      "         [-0.01030956, -0.00185656,  0.06213117, ...,  0.01312048,\n",
      "          -0.0377509 , -0.0577291 ]]]], dtype=float32), array([[8.7697332e-04, 4.2944841e-04, 3.8611881e-02, 4.5042118e-01,\n",
      "        2.0880094e-02, 3.0573282e-01, 1.6604018e-01, 1.6066436e-02,\n",
      "        5.2239379e-04, 4.1856553e-04]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# two ways: use intermediate layers or create multiple models, try the second one, this works\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "from keras.losses import KLDivergence\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import keras\n",
    "from keract import get_activations\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Add, Activation, Dropout, Flatten, Dense\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "#import wide_residual_network as wrn\n",
    "from keras.datasets import cifar10\n",
    "import keras.callbacks as callbacks\n",
    "import keras.utils.np_utils as kutils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Concatenate\n",
    "from keras import backend as K\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "weight_decay = 0.0005\n",
    "\n",
    "def initial_conv(input):\n",
    "    x = Convolution2D(16, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(input)\n",
    "\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def expand_conv(init, base, k, strides=(1, 1)):\n",
    "    x = Convolution2D(base * k, (3, 3), padding='same', strides=strides, kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(init)\n",
    "\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Convolution2D(base * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    skip = Convolution2D(base * k, (1, 1), padding='same', strides=strides, kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(init)\n",
    "\n",
    "    m = Add()([x, skip])\n",
    "\n",
    "    return m\n",
    "\n",
    "\n",
    "def conv1_block(input, k=1, dropout=0.0):\n",
    "    init = input\n",
    "\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    m = Add()([init, x])\n",
    "    return m\n",
    "\n",
    "def conv2_block(input, k=1, dropout=0.0):\n",
    "    init = input\n",
    "\n",
    "    #channel_axis = 1 if K.image_dim_ordering() == \"th\" else -1\n",
    "    channel_axis = -1\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    m = Add()([init, x])\n",
    "    return m\n",
    "\n",
    "def conv3_block(input, k=1, dropout=0.0):\n",
    "    init = input\n",
    "\n",
    "    #channel_axis = 1 if K.image_dim_ordering() == \"th\" else -1\n",
    "    channel_axis = -1\n",
    "    \n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    m = Add()([init, x])\n",
    "    return m\n",
    "\n",
    "def create_wide_residual_network(input_dim, nb_classes=100, N=2, k=1, dropout=0.0, verbose=1):\n",
    "    \"\"\"\n",
    "    Creates a Wide Residual Network with specified parameters\n",
    "\n",
    "    :param input: Input Keras object\n",
    "    :param nb_classes: Number of output classes\n",
    "    :param N: Depth of the network. Compute N = (n - 4) / 6.\n",
    "              Example : For a depth of 16, n = 16, N = (16 - 4) / 6 = 2\n",
    "              Example2: For a depth of 28, n = 28, N = (28 - 4) / 6 = 4\n",
    "              Example3: For a depth of 40, n = 40, N = (40 - 4) / 6 = 6\n",
    "    :param k: Width of the network.\n",
    "    :param dropout: Adds dropout if value is greater than 0.0\n",
    "    :param verbose: Debug info to describe created WRN\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "\n",
    "    ip = Input(shape=input_dim)\n",
    "\n",
    "    x = initial_conv(ip)\n",
    "    nb_conv = 4\n",
    "\n",
    "    x = expand_conv(x, 16, k)\n",
    "    nb_conv += 2\n",
    "\n",
    "    for i in range(N - 1):\n",
    "        x = conv1_block(x, k, dropout)\n",
    "        nb_conv += 2\n",
    "\n",
    "    print('First activation summary')\n",
    "    out1 = x\n",
    "        \n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = expand_conv(x, 32, k, strides=(2, 2))\n",
    "    nb_conv += 2\n",
    "    \n",
    "    \n",
    "\n",
    "    for i in range(N - 1):\n",
    "        x = conv2_block(x, k, dropout)\n",
    "        nb_conv += 2\n",
    "        \n",
    "    print('Second activation summary')\n",
    "    out2 = x\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = expand_conv(x, 64, k, strides=(2, 2))\n",
    "    nb_conv += 2\n",
    "\n",
    "    for i in range(N - 1):\n",
    "        x = conv3_block(x, k, dropout)\n",
    "        nb_conv += 2\n",
    "    \n",
    "    print('Third activation summary')\n",
    "    out3 = x\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = AveragePooling2D((8, 8))(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(nb_classes, W_regularizer=l2(weight_decay), activation='softmax')(x)\n",
    "    \n",
    "    #model = Model(ip, [x,out1,out2,out3])\n",
    "    model = Model(ip,x)\n",
    "    \n",
    "    m1 = Model(ip,[out1,x])\n",
    "    m2 = Model(ip,[out2,x])\n",
    "    m3 = Model(ip,[out3,x])\n",
    "\n",
    "    if verbose: print(\"Wide Residual Network-%d-%d created.\" % (nb_conv, k))\n",
    "    return model,m1,m2,m3\n",
    "\n",
    "\n",
    "'''\n",
    "Function that returns the trainand test data of the CIFAR10 already preprocessed\n",
    "'''\n",
    "def getCIFAR10():\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = 32, 32\n",
    "    num_classes = 10\n",
    "\n",
    "    # the data, split between train and test sets\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    \n",
    "    # format of the tensor\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
    "        x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
    "        input_shape = (3, img_rows, img_cols)\n",
    "    else:\n",
    "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "        input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "    # convert in to float the images\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    \n",
    "    # new normalization with z-score\n",
    "    mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "    std = np.std(x_train,axis=(0,1,2,3))\n",
    "    x_train = (x_train-mean)/(std+1e-7)\n",
    "    x_test = (x_test-mean)/(std+1e-7)\n",
    "    \n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    print('CIFAR10 loaded')\n",
    "    return x_train,y_train,x_test,y_test\n",
    "\n",
    "'''\n",
    "Small function that returns the shape of the CIFAR10 images\n",
    "'''\n",
    "def getCIFAR10InputShape():\n",
    "    img_rows, img_cols = 32, 32\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (3, img_rows, img_cols)\n",
    "    else:\n",
    "        input_shape = (img_rows, img_cols, 3)\n",
    "        \n",
    "    return input_shape\n",
    "\n",
    "def getNetwork(input_shape):\n",
    "    model=create_wide_residual_network(input_shape, 10, N=2, k=1, dropout=0.)\n",
    "    #plot_model(model, \"WRN-16-1.png\", show_shapes=True, show_layer_names=True)\n",
    "    return model;\n",
    "\n",
    "def myLoss(y_true,y_pred):\n",
    "    \n",
    "    real_pred = y_pred\n",
    "    real_true = y_true\n",
    "    \n",
    "    loss = keras.losses.categorical_crossentropy(real_true,real_pred)\n",
    "    \n",
    "    return loss;\n",
    "\n",
    "def useless_loss(y_true,y_pred):\n",
    "    \n",
    "    zer = K.zeros(1)\n",
    "    \n",
    "    return zer\n",
    "\n",
    "def myaccuracy(y_true, y_pred):\n",
    "    \n",
    "    real_pred = y_pred[0]\n",
    "    real_true = y_true[0]\n",
    "    \n",
    "    return keras.metrics.categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "'''\n",
    "Function to try to train the network on CIFAR10\n",
    "'''\n",
    "def trainNetwork(epochs):\n",
    "    batch_size = 128\n",
    "    epochs = 2\n",
    "    x_train,y_train,x_test,y_test = getCIFAR10()\n",
    "    \n",
    "    input_shape = getCIFAR10InputShape()\n",
    "    print('CIFAR10 shape: ' + str(input_shape))\n",
    "    \n",
    "    model,m1,m2,m3 = getNetwork(input_shape)\n",
    "    \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "    \n",
    "    m1.compile(loss=[useless_loss,useless_loss],optimizer='sgd')\n",
    "    m2.compile(loss=[useless_loss,useless_loss],optimizer='sgd')\n",
    "    m3.compile(loss=[useless_loss,useless_loss],optimizer='sgd')\n",
    "    \n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "    \n",
    "    model_predictions = model.predict(x_train[0:1])\n",
    "    m1_predictions = m1.predict(x_train[0:1])\n",
    "    m2_predictions = m2.predict(x_train[0:1])\n",
    "    m3_predictions = m3.predict(x_train[0:1])\n",
    "    \n",
    "    print('Full model predictions:')\n",
    "    print(str(model_predictions))\n",
    "    print(\"Model 1 predictions:\")\n",
    "    print(str(m1_predictions))\n",
    "    \n",
    "    print(\"Model 2 predictions:\")\n",
    "    print(str(m2_predictions))\n",
    "    \n",
    "    print(\"Model 3 predictions:\")\n",
    "    print(str(m3_predictions))\n",
    "\n",
    "def main():\n",
    "    trainNetwork(5)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10 loaded\n",
      "CIFAR10 shape: (32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:77: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), padding=\"same\", strides=(1, 1), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:86: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:90: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), padding=\"same\", strides=(1, 1), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:106: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:114: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:77: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", strides=(2, 2), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First activation summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:86: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:90: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), padding=\"same\", strides=(2, 2), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:129: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:137: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second activation summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:77: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", strides=(2, 2), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:86: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:90: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), padding=\"same\", strides=(2, 2), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:152: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:160: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "/home/test/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/ipykernel_launcher.py:231: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, activation=\"softmax\", kernel_regularizer=<keras.reg...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Third activation summary\n",
      "Untrained\n",
      "Full model predictions:\n",
      "[[0.09999997 0.10000002 0.10000002 0.10000012 0.09999997 0.09999996\n",
      "  0.09999995 0.10000005 0.09999994 0.09999998]]\n",
      "Model 1 predictions:\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "50000/50000 [==============================] - 29s 572us/step - loss: 1.8074 - acc: 0.4328 - val_loss: 1.2941 - val_acc: 0.5882\n",
      "Epoch 2/3\n",
      "50000/50000 [==============================] - 26s 525us/step - loss: 1.1695 - acc: 0.6392 - val_loss: 1.1119 - val_acc: 0.6571\n",
      "Epoch 3/3\n",
      "50000/50000 [==============================] - 26s 514us/step - loss: 1.0060 - acc: 0.6987 - val_loss: 0.9894 - val_acc: 0.7025\n",
      "After full model training\n",
      "Full model predictions:\n",
      "[[2.0413179e-04 8.8914043e-05 1.0133072e-02 2.6488888e-01 2.2332121e-02\n",
      "  3.7137428e-01 3.2029131e-01 1.0307656e-02 2.8539321e-04 9.4255782e-05]]\n",
      "Model 1 predictions:\n",
      "[[2.0413179e-04 8.8914043e-05 1.0133072e-02 2.6488888e-01 2.2332121e-02\n",
      "  3.7137428e-01 3.2029131e-01 1.0307656e-02 2.8539321e-04 9.4255782e-05]]\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "50000/50000 [==============================] - 29s 579us/step - loss: 0.8859 - acc: 0.7430 - val_loss: 0.9053 - val_acc: 0.7372\n",
      "Epoch 2/3\n",
      "50000/50000 [==============================] - 27s 536us/step - loss: 0.8105 - acc: 0.7704 - val_loss: 0.8615 - val_acc: 0.7553\n",
      "Epoch 3/3\n",
      "50000/50000 [==============================] - 26s 529us/step - loss: 0.7533 - acc: 0.7920 - val_loss: 0.8179 - val_acc: 0.7705\n",
      "After model 1 training\n",
      "Full model predictions:\n",
      "[[8.4435480e-04 1.7966880e-04 5.5168971e-02 6.6091329e-02 1.0201749e-02\n",
      "  8.5112095e-02 7.7819419e-01 3.6718380e-03 3.1834468e-04 2.1749425e-04]]\n",
      "Model 1 predictions:\n",
      "[[8.4435480e-04 1.7966880e-04 5.5168971e-02 6.6091329e-02 1.0201749e-02\n",
      "  8.5112095e-02 7.7819419e-01 3.6718380e-03 3.1834468e-04 2.1749425e-04]]\n"
     ]
    }
   ],
   "source": [
    "# try to train two model with the same in/out, it updates the weights of both\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "from keras.losses import KLDivergence\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import keras\n",
    "from keract import get_activations\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Add, Activation, Dropout, Flatten, Dense\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "#import wide_residual_network as wrn\n",
    "from keras.datasets import cifar10\n",
    "import keras.callbacks as callbacks\n",
    "import keras.utils.np_utils as kutils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Concatenate\n",
    "from keras import backend as K\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "weight_decay = 0.0005\n",
    "\n",
    "def initial_conv(input):\n",
    "    x = Convolution2D(16, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(input)\n",
    "\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def expand_conv(init, base, k, strides=(1, 1)):\n",
    "    x = Convolution2D(base * k, (3, 3), padding='same', strides=strides, kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(init)\n",
    "\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Convolution2D(base * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    skip = Convolution2D(base * k, (1, 1), padding='same', strides=strides, kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(init)\n",
    "\n",
    "    m = Add()([x, skip])\n",
    "\n",
    "    return m\n",
    "\n",
    "\n",
    "def conv1_block(input, k=1, dropout=0.0):\n",
    "    init = input\n",
    "\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(16 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    m = Add()([init, x])\n",
    "    return m\n",
    "\n",
    "def conv2_block(input, k=1, dropout=0.0):\n",
    "    init = input\n",
    "\n",
    "    #channel_axis = 1 if K.image_dim_ordering() == \"th\" else -1\n",
    "    channel_axis = -1\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(32 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    m = Add()([init, x])\n",
    "    return m\n",
    "\n",
    "def conv3_block(input, k=1, dropout=0.0):\n",
    "    init = input\n",
    "\n",
    "    #channel_axis = 1 if K.image_dim_ordering() == \"th\" else -1\n",
    "    channel_axis = -1\n",
    "    \n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(input)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    if dropout > 0.0: x = Dropout(dropout)(x)\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(64 * k, (3, 3), padding='same', kernel_initializer='he_normal',\n",
    "                      W_regularizer=l2(weight_decay),\n",
    "                      use_bias=False)(x)\n",
    "\n",
    "    m = Add()([init, x])\n",
    "    return m\n",
    "\n",
    "def create_wide_residual_network(input_dim, nb_classes=100, N=2, k=1, dropout=0.0, verbose=1):\n",
    "    \"\"\"\n",
    "    Creates a Wide Residual Network with specified parameters\n",
    "\n",
    "    :param input: Input Keras object\n",
    "    :param nb_classes: Number of output classes\n",
    "    :param N: Depth of the network. Compute N = (n - 4) / 6.\n",
    "              Example : For a depth of 16, n = 16, N = (16 - 4) / 6 = 2\n",
    "              Example2: For a depth of 28, n = 28, N = (28 - 4) / 6 = 4\n",
    "              Example3: For a depth of 40, n = 40, N = (40 - 4) / 6 = 6\n",
    "    :param k: Width of the network.\n",
    "    :param dropout: Adds dropout if value is greater than 0.0\n",
    "    :param verbose: Debug info to describe created WRN\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "\n",
    "    ip = Input(shape=input_dim)\n",
    "\n",
    "    x = initial_conv(ip)\n",
    "    nb_conv = 4\n",
    "\n",
    "    x = expand_conv(x, 16, k)\n",
    "    nb_conv += 2\n",
    "\n",
    "    for i in range(N - 1):\n",
    "        x = conv1_block(x, k, dropout)\n",
    "        nb_conv += 2\n",
    "\n",
    "    print('First activation summary')\n",
    "    out1 = x\n",
    "        \n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = expand_conv(x, 32, k, strides=(2, 2))\n",
    "    nb_conv += 2\n",
    "    \n",
    "    \n",
    "\n",
    "    for i in range(N - 1):\n",
    "        x = conv2_block(x, k, dropout)\n",
    "        nb_conv += 2\n",
    "        \n",
    "    print('Second activation summary')\n",
    "    out2 = x\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = expand_conv(x, 64, k, strides=(2, 2))\n",
    "    nb_conv += 2\n",
    "\n",
    "    for i in range(N - 1):\n",
    "        x = conv3_block(x, k, dropout)\n",
    "        nb_conv += 2\n",
    "    \n",
    "    print('Third activation summary')\n",
    "    out3 = x\n",
    "\n",
    "    x = BatchNormalization(axis=channel_axis, momentum=0.1, epsilon=1e-5, gamma_initializer='uniform')(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = AveragePooling2D((8, 8))(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(nb_classes, W_regularizer=l2(weight_decay), activation='softmax')(x)\n",
    "    \n",
    "    #model = Model(ip, [x,out1,out2,out3])\n",
    "    model = Model(ip,x)\n",
    "    \n",
    "    m1 = Model(ip,x)\n",
    "\n",
    "    return model,m1\n",
    "\n",
    "\n",
    "'''\n",
    "Function that returns the trainand test data of the CIFAR10 already preprocessed\n",
    "'''\n",
    "def getCIFAR10():\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = 32, 32\n",
    "    num_classes = 10\n",
    "\n",
    "    # the data, split between train and test sets\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    \n",
    "    # format of the tensor\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
    "        x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
    "        input_shape = (3, img_rows, img_cols)\n",
    "    else:\n",
    "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "        input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "    # convert in to float the images\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    \n",
    "    # new normalization with z-score\n",
    "    mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "    std = np.std(x_train,axis=(0,1,2,3))\n",
    "    x_train = (x_train-mean)/(std+1e-7)\n",
    "    x_test = (x_test-mean)/(std+1e-7)\n",
    "    \n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    print('CIFAR10 loaded')\n",
    "    return x_train,y_train,x_test,y_test\n",
    "\n",
    "'''\n",
    "Small function that returns the shape of the CIFAR10 images\n",
    "'''\n",
    "def getCIFAR10InputShape():\n",
    "    img_rows, img_cols = 32, 32\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (3, img_rows, img_cols)\n",
    "    else:\n",
    "        input_shape = (img_rows, img_cols, 3)\n",
    "        \n",
    "    return input_shape\n",
    "\n",
    "def getNetwork(input_shape):\n",
    "    model=create_wide_residual_network(input_shape, 10, N=2, k=1, dropout=0.)\n",
    "    #plot_model(model, \"WRN-16-1.png\", show_shapes=True, show_layer_names=True)\n",
    "    return model;\n",
    "\n",
    "def myLoss(y_true,y_pred):\n",
    "    \n",
    "    real_pred = y_pred\n",
    "    real_true = y_true\n",
    "    \n",
    "    loss = keras.losses.categorical_crossentropy(real_true,real_pred)\n",
    "    \n",
    "    return loss;\n",
    "\n",
    "def useless_loss(y_true,y_pred):\n",
    "    \n",
    "    zer = K.zeros(1)\n",
    "    \n",
    "    return zer\n",
    "\n",
    "def myaccuracy(y_true, y_pred):\n",
    "    \n",
    "    real_pred = y_pred[0]\n",
    "    real_true = y_true[0]\n",
    "    \n",
    "    return keras.metrics.categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "'''\n",
    "Function to try to train the network on CIFAR10\n",
    "'''\n",
    "def trainNetwork(epochs):\n",
    "    \n",
    "    x_train,y_train,x_test,y_test = getCIFAR10()\n",
    "    \n",
    "    batch_size = 128\n",
    "    epochs = 3\n",
    "    n_batches = math.floor( x_train.shape[0] / batch_size)\n",
    "    \n",
    "    input_shape = getCIFAR10InputShape()\n",
    "    print('CIFAR10 shape: ' + str(input_shape))\n",
    "    \n",
    "    model,m1 = getNetwork(input_shape)\n",
    "    \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "    \n",
    "    m1.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "    \n",
    "    print('Untrained')\n",
    "    model_predictions = model.predict(x_train[0:1])\n",
    "    m1_predictions = m1.predict(x_train[0:1])\n",
    "    \n",
    "    print('Full model predictions:')\n",
    "    print(str(model_predictions))\n",
    "    print(\"Model 1 predictions:\")\n",
    "    print(str(m1_predictions))\n",
    "    \n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "    \n",
    "    print('After full model training')\n",
    "    model_predictions = model.predict(x_train[0:1])\n",
    "    m1_predictions = m1.predict(x_train[0:1])\n",
    "    \n",
    "    print('Full model predictions:')\n",
    "    print(str(model_predictions))\n",
    "    print(\"Model 1 predictions:\")\n",
    "    print(str(m1_predictions))\n",
    "    \n",
    "    m1.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "    \n",
    "    print('After model 1 training')\n",
    "    model_predictions = model.predict(x_train[0:1])\n",
    "    m1_predictions = m1.predict(x_train[0:1])\n",
    "    \n",
    "    print('Full model predictions:')\n",
    "    print(str(model_predictions))\n",
    "    print(\"Model 1 predictions:\")\n",
    "    print(str(m1_predictions))\n",
    "\n",
    "def main():\n",
    "    trainNetwork(5)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_gpuenv",
   "language": "python",
   "name": "tensorflow_gpuenv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
