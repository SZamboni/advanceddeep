{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10 loaded\n",
      "CIFAR10 shape: (32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/test/advanceddeep/our_code/ourwrnet.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "  use_bias=False)(input)\n",
      "/home/test/advanceddeep/our_code/ourwrnet.py:52: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", strides=(1, 1), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "  use_bias=False)(init)\n",
      "/home/test/advanceddeep/our_code/ourwrnet.py:61: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "  use_bias=False)(x)\n",
      "/home/test/advanceddeep/our_code/ourwrnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1), padding=\"same\", strides=(1, 1), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "  use_bias=False)(init)\n",
      "/home/test/advanceddeep/our_code/ourwrnet.py:81: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "  use_bias=False)(x)\n",
      "/home/test/advanceddeep/our_code/ourwrnet.py:89: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "  use_bias=False)(x)\n",
      "/home/test/advanceddeep/our_code/ourwrnet.py:52: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", strides=(2, 2), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "  use_bias=False)(init)\n",
      "/home/test/advanceddeep/our_code/ourwrnet.py:61: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "  use_bias=False)(x)\n",
      "/home/test/advanceddeep/our_code/ourwrnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), padding=\"same\", strides=(2, 2), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "  use_bias=False)(init)\n",
      "/home/test/advanceddeep/our_code/ourwrnet.py:104: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "  use_bias=False)(x)\n",
      "/home/test/advanceddeep/our_code/ourwrnet.py:112: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "  use_bias=False)(x)\n",
      "/home/test/advanceddeep/our_code/ourwrnet.py:52: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", strides=(2, 2), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "  use_bias=False)(init)\n",
      "/home/test/advanceddeep/our_code/ourwrnet.py:61: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "  use_bias=False)(x)\n",
      "/home/test/advanceddeep/our_code/ourwrnet.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), padding=\"same\", strides=(2, 2), kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "  use_bias=False)(init)\n",
      "/home/test/advanceddeep/our_code/ourwrnet.py:127: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "  use_bias=False)(x)\n",
      "/home/test/advanceddeep/our_code/ourwrnet.py:135: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False, kernel_regularizer=<keras.reg...)`\n",
      "  use_bias=False)(x)\n",
      "/home/test/advanceddeep/our_code/ourwrnet.py:207: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, activation=\"softmax\", kernel_regularizer=<keras.reg...)`\n",
      "  x = Dense(nb_classes, W_regularizer=l2(weight_decay), activation='softmax')(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wide Residual Network-16-2 created.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 39s 788us/step - loss: 2.4059 - acc: 0.4184 - val_loss: 1.9629 - val_acc: 0.5222\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 37s 745us/step - loss: 1.5548 - acc: 0.6295 - val_loss: 1.3738 - val_acc: 0.6620\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 37s 744us/step - loss: 1.1979 - acc: 0.7076 - val_loss: 1.1069 - val_acc: 0.7275\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 37s 742us/step - loss: 1.0055 - acc: 0.7547 - val_loss: 0.9512 - val_acc: 0.7666\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.8841 - acc: 0.7844 - val_loss: 0.9005 - val_acc: 0.7787\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.8041 - acc: 0.8078 - val_loss: 0.8283 - val_acc: 0.7983\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 37s 744us/step - loss: 0.7347 - acc: 0.8277 - val_loss: 0.8050 - val_acc: 0.8072\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 37s 742us/step - loss: 0.6952 - acc: 0.8371 - val_loss: 0.8014 - val_acc: 0.8052\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 37s 742us/step - loss: 0.6537 - acc: 0.8513 - val_loss: 0.7766 - val_acc: 0.8125\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.6256 - acc: 0.8612 - val_loss: 0.7799 - val_acc: 0.8133\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.5968 - acc: 0.8710 - val_loss: 0.7505 - val_acc: 0.8233\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 37s 740us/step - loss: 0.5687 - acc: 0.8805 - val_loss: 0.7404 - val_acc: 0.8240\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 37s 743us/step - loss: 0.5467 - acc: 0.8886 - val_loss: 0.7680 - val_acc: 0.8159\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 37s 742us/step - loss: 0.5289 - acc: 0.8944 - val_loss: 0.7825 - val_acc: 0.8215\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.5106 - acc: 0.9027 - val_loss: 0.7716 - val_acc: 0.8192\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.4926 - acc: 0.9083 - val_loss: 0.8352 - val_acc: 0.8130\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 37s 740us/step - loss: 0.4773 - acc: 0.9150 - val_loss: 0.7929 - val_acc: 0.8245\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.4572 - acc: 0.9212 - val_loss: 0.7820 - val_acc: 0.8232\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 37s 742us/step - loss: 0.4356 - acc: 0.9296 - val_loss: 0.8673 - val_acc: 0.8081\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.4357 - acc: 0.9296 - val_loss: 0.7750 - val_acc: 0.8340\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.4168 - acc: 0.9365 - val_loss: 0.7822 - val_acc: 0.8302\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.4019 - acc: 0.9395 - val_loss: 0.8097 - val_acc: 0.8254\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.3911 - acc: 0.9438 - val_loss: 0.8266 - val_acc: 0.8232\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 37s 742us/step - loss: 0.3703 - acc: 0.9511 - val_loss: 0.8222 - val_acc: 0.8224\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 37s 740us/step - loss: 0.3613 - acc: 0.9542 - val_loss: 0.8296 - val_acc: 0.8235\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 37s 743us/step - loss: 0.3597 - acc: 0.9537 - val_loss: 0.8152 - val_acc: 0.8288\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 37s 742us/step - loss: 0.3452 - acc: 0.9586 - val_loss: 0.8327 - val_acc: 0.8252\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 37s 740us/step - loss: 0.3361 - acc: 0.9610 - val_loss: 0.8493 - val_acc: 0.8229\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.3330 - acc: 0.9611 - val_loss: 0.8437 - val_acc: 0.8264\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.3204 - acc: 0.9651 - val_loss: 0.8068 - val_acc: 0.8325\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 37s 742us/step - loss: 0.3203 - acc: 0.9644 - val_loss: 0.8785 - val_acc: 0.8174\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 37s 740us/step - loss: 0.2578 - acc: 0.9888 - val_loss: 0.7493 - val_acc: 0.8463\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.2265 - acc: 0.9985 - val_loss: 0.7743 - val_acc: 0.8452\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.2175 - acc: 0.9995 - val_loss: 0.7385 - val_acc: 0.8506\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 37s 742us/step - loss: 0.2117 - acc: 0.9997 - val_loss: 0.7649 - val_acc: 0.8484\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.2068 - acc: 0.9999 - val_loss: 0.7692 - val_acc: 0.8450\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.2019 - acc: 1.0000 - val_loss: 0.7492 - val_acc: 0.8501\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 37s 740us/step - loss: 0.1982 - acc: 0.9999 - val_loss: 0.7735 - val_acc: 0.8439\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 37s 743us/step - loss: 0.1944 - acc: 0.9999 - val_loss: 0.7660 - val_acc: 0.8450\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.1906 - acc: 1.0000 - val_loss: 0.7529 - val_acc: 0.8498\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 37s 742us/step - loss: 0.1873 - acc: 1.0000 - val_loss: 0.7692 - val_acc: 0.8478\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 37s 742us/step - loss: 0.1841 - acc: 1.0000 - val_loss: 0.7725 - val_acc: 0.8440\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 37s 743us/step - loss: 0.1810 - acc: 1.0000 - val_loss: 0.8246 - val_acc: 0.8384\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.1782 - acc: 1.0000 - val_loss: 0.7693 - val_acc: 0.8454\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.1754 - acc: 1.0000 - val_loss: 0.7837 - val_acc: 0.8429\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 37s 744us/step - loss: 0.1728 - acc: 1.0000 - val_loss: 0.7950 - val_acc: 0.8389\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 37s 742us/step - loss: 0.1704 - acc: 1.0000 - val_loss: 0.7358 - val_acc: 0.8504\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.1676 - acc: 1.0000 - val_loss: 0.7263 - val_acc: 0.8503\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 37s 742us/step - loss: 0.1652 - acc: 1.0000 - val_loss: 0.7448 - val_acc: 0.8475\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 37s 743us/step - loss: 0.1631 - acc: 1.0000 - val_loss: 0.7079 - val_acc: 0.8523\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 37s 743us/step - loss: 0.1607 - acc: 1.0000 - val_loss: 0.7536 - val_acc: 0.8432\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 37s 742us/step - loss: 0.1585 - acc: 1.0000 - val_loss: 0.7462 - val_acc: 0.8455\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 37s 744us/step - loss: 0.1565 - acc: 1.0000 - val_loss: 0.7331 - val_acc: 0.8455\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.1545 - acc: 1.0000 - val_loss: 0.7566 - val_acc: 0.8400\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 37s 744us/step - loss: 0.1525 - acc: 1.0000 - val_loss: 0.7332 - val_acc: 0.8470\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 37s 742us/step - loss: 0.1507 - acc: 1.0000 - val_loss: 0.7512 - val_acc: 0.8439\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 37s 741us/step - loss: 0.1487 - acc: 1.0000 - val_loss: 0.7466 - val_acc: 0.8431\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 37s 743us/step - loss: 0.1470 - acc: 1.0000 - val_loss: 0.7323 - val_acc: 0.8430\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 37s 742us/step - loss: 0.1453 - acc: 1.0000 - val_loss: 0.7680 - val_acc: 0.8382\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 37s 743us/step - loss: 0.1437 - acc: 1.0000 - val_loss: 0.7233 - val_acc: 0.8460\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 37s 744us/step - loss: 0.1420 - acc: 1.0000 - val_loss: 0.7264 - val_acc: 0.8460\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 37s 742us/step - loss: 0.1410 - acc: 1.0000 - val_loss: 0.7425 - val_acc: 0.8410\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 37s 744us/step - loss: 0.1406 - acc: 1.0000 - val_loss: 0.7141 - val_acc: 0.8464\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 37s 743us/step - loss: 0.1402 - acc: 1.0000 - val_loss: 0.7124 - val_acc: 0.8482\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 37s 743us/step - loss: 0.1399 - acc: 1.0000 - val_loss: 0.7051 - val_acc: 0.8517\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 37s 743us/step - loss: 0.1396 - acc: 1.0000 - val_loss: 0.7304 - val_acc: 0.8415\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 37s 742us/step - loss: 0.1393 - acc: 1.0000 - val_loss: 0.7097 - val_acc: 0.8451\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 37s 744us/step - loss: 0.1391 - acc: 1.0000 - val_loss: 0.7220 - val_acc: 0.8466\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 37s 743us/step - loss: 0.1387 - acc: 1.0000 - val_loss: 0.7344 - val_acc: 0.8432\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 37s 742us/step - loss: 0.1384 - acc: 1.0000 - val_loss: 0.7146 - val_acc: 0.8470\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 37s 742us/step - loss: 0.1382 - acc: 1.0000 - val_loss: 0.7256 - val_acc: 0.8445\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 37s 743us/step - loss: 0.1379 - acc: 1.0000 - val_loss: 0.7772 - val_acc: 0.8351\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 37s 743us/step - loss: 0.1377 - acc: 1.0000 - val_loss: 0.7522 - val_acc: 0.8414\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 37s 745us/step - loss: 0.1372 - acc: 1.0000 - val_loss: 0.7127 - val_acc: 0.8475\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 37s 742us/step - loss: 0.1370 - acc: 1.0000 - val_loss: 0.7157 - val_acc: 0.8453\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 37s 742us/step - loss: 0.1369 - acc: 1.0000 - val_loss: 0.7221 - val_acc: 0.8454\n",
      "Epoch 77/100\n",
      " 3072/50000 [>.............................] - ETA: 32s - loss: 0.1365 - acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e1a040991679>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0msaveModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wrn_16_2_layer3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-e1a040991679>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    173\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m          callbacks=[LearningRateScheduler(lr_schedule)])\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0mmodel_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_gpuenv/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from ourwrnet import *\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "from keras.losses import KLDivergence\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import keras\n",
    "from keract import get_activations\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Add, Activation, Dropout, Flatten, Dense\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "#import wide_residual_network as wrn\n",
    "from keras.datasets import cifar10\n",
    "import keras.callbacks as callbacks\n",
    "import keras.utils.np_utils as kutils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Concatenate\n",
    "from keras import backend as K\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "'''\n",
    "Function that returns the trainand test data of the CIFAR10 already preprocessed\n",
    "'''\n",
    "def getCIFAR10():\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = 32, 32\n",
    "    num_classes = 10\n",
    "\n",
    "    # the data, split between train and test sets\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    \n",
    "    # format of the tensor\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
    "        x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
    "        input_shape = (3, img_rows, img_cols)\n",
    "    else:\n",
    "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "        input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "    # convert in to float the images\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    \n",
    "    # new normalization with z-score\n",
    "    mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "    std = np.std(x_train,axis=(0,1,2,3))\n",
    "    x_train = (x_train-mean)/(std+1e-7)\n",
    "    x_test = (x_test-mean)/(std+1e-7)\n",
    "    \n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    print('CIFAR10 loaded')\n",
    "    return x_train,y_train,x_test,y_test\n",
    "\n",
    "\n",
    "'''\n",
    "Function that returns the shape of the CIFAR10 images\n",
    "'''\n",
    "def getCIFAR10InputShape():\n",
    "    img_rows, img_cols = 32, 32\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (3, img_rows, img_cols)\n",
    "    else:\n",
    "        input_shape = (img_rows, img_cols, 3)\n",
    "        \n",
    "    return input_shape\n",
    "\n",
    "'''\n",
    "Function that returns the network to train\n",
    "'''\n",
    "def getNetwork(input_shape):\n",
    "    model, m1, m2, m3=create_wide_residual_network(input_shape, 10, N=2, k=2, dropout=0.)\n",
    "    return model,m1,m2,m3;\n",
    "\n",
    "'''\n",
    "Function that saves a model on the disk\n",
    "'''\n",
    "def saveModel(model,filename):\n",
    "    model_json = model.to_json()\n",
    "    with open(filename + '.json', 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(filename + '.h5') \n",
    "\n",
    "'''\n",
    "Learning rate scheduler\n",
    "'''\n",
    "def lr_schedule(epoch):\n",
    "    total_epochs = 100\n",
    "    lrate = 0.1\n",
    "    if epoch > total_epochs*0.3:\n",
    "        lrate = 0.02\n",
    "    if epoch > total_epochs*0.6:\n",
    "        lrate = 0.004\n",
    "    if epoch > total_epochs*0.8:\n",
    "        lrate = 0.0008\n",
    "    return lrate\n",
    "\n",
    "'''\n",
    "Placeholder loss\n",
    "'''\n",
    "def useless_loss(y_true,y_pred):\n",
    "    zer = K.zeros(1)\n",
    "    \n",
    "    return zer\n",
    "    \n",
    "'''\n",
    "Function to try to train the network on CIFAR10\n",
    "'''\n",
    "def main():\n",
    "    epochs = 100\n",
    "    batch_size = 128\n",
    "    x_train,y_train,x_test,y_test = getCIFAR10()\n",
    "    \n",
    "    input_shape = getCIFAR10InputShape()\n",
    "    print('CIFAR10 shape: ' + str(input_shape))\n",
    "    \n",
    "    model,m1,m2,m3 = getNetwork(input_shape)\n",
    "    \n",
    "    # define optimizer\n",
    "    optim_sgd = optimizers.SGD(lr=0.1, decay=5e-4, momentum=0.9)\n",
    "    \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=optim_sgd, metrics=[\"acc\"])\n",
    "    \n",
    "    m1.compile(loss=[useless_loss,useless_loss],optimizer='sgd')\n",
    "    m2.compile(loss=[useless_loss,useless_loss],optimizer='sgd')\n",
    "    m3.compile(loss=[useless_loss,useless_loss],optimizer='sgd')\n",
    "    \n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=45,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "    )\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(\n",
    "        datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "        epochs=epochs,\n",
    "        validation_data=(x_test, y_test),\n",
    "        workers=4,\n",
    "        shuffle=True,\n",
    "        callbacks=[LearningRateScheduler(lr_schedule)])\n",
    "    \n",
    "    model_predictions = model.predict(x_train[0:1])\n",
    "    m1_predictions = m1.predict(x_train[0:1])\n",
    "    m2_predictions = m2.predict(x_train[0:1])\n",
    "    m3_predictions = m3.predict(x_train[0:1])\n",
    "    \n",
    "    print('Full model predictions:')\n",
    "    #print(str(model_predictions))\n",
    "    print(\"Model 1 predictions:\")\n",
    "    #print(str(m1_predictions))\n",
    "    print(\"Model 2 predictions:\")\n",
    "    #print(str(m2_predictions))\n",
    "    print(\"Model 3 predictions:\")\n",
    "    #print(str(m3_predictions))\n",
    "    \n",
    "    saveModel(model,'wrn_16_2')\n",
    "    saveModel(m1,'wrn_16_2_layer1')\n",
    "    saveModel(m2,'wrn_16_2_layer2')\n",
    "    saveModel(m3,'wrn_16_2_layer3')\n",
    "    \n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_gpuenv",
   "language": "python",
   "name": "tensorflow_gpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
